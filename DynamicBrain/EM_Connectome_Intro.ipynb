{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">EM Connectomics</h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">Tuesday, August 27, 2019</h3> \n",
    "\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>In this session, we introduce how to query the anotation database and give a flavor of how to use the results to do some simple analysis. By the end, you should be able to query for neurons, query for synapses between those neurons, and visualize the neurons and synapes.\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Background</h2>\n",
    "\n",
    "<p>\n",
    "This dataset is part of a collaboration between the Tolias lab at Baylor,\n",
    "the Allen Institute, and Sebastian Seung's lab at Princeton University,\n",
    "as part of the IARPA Microns project.  It is unpublished data that the \n",
    "group is hoping to be published in the near future.  The collaboration \n",
    "aims to make this dataset public post-publication, and so we are excited\n",
    "to get your feedback on how you might interact with the data programatically.\n",
    "\n",
    "However, this also means that if you are interested in working with this\n",
    "data outside of the course you will need to setup a collaboration agreement\n",
    "with the larger group, and will need to return your USB drive at the end of the course.\n",
    "</p>\n",
    "</div>\n",
    "\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Local setup instructions</h2>\n",
    "\n",
    "<p>\n",
    "Because this dataset is part of a collaboration, it has not been packaged \n",
    "through the usual AllenSDK mechanism.  Working with Princeton we have developed two packages for querying and visualizing the data.  If you want to setup your local computer's python system to use these packages you'll need to install them and their dependancies. \n",
    "</p>\n",
    "\n",
    "<p>\n",
    "The easiest way to install is to use Anaconda python.  Open up a terminal, or a command prompt on windows.  Navigate to the directory where you have checked out the swdb_2019 repository. Activate a conda environment if you'd like then type..\n",
    "\n",
    "</div>\n",
    "<h4>Linux/OSX</h4>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "./scripts/em_conda_install.sh\n",
    "</div>\n",
    "<h4>Windows</h4>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #DFF0D8; \">\n",
    "./scripts/em_conda_install.bat\n",
    "</div>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "You'll need to restart your kernel after you do the install\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Drive Path</h2>\n",
    "First we need to know where the data is on your system.  If you are running on Linux or Windows, edit this cell to reflect where the data is.  If on AWS or mac the location here is likely correct.\n",
    "\n",
    "We also need to decide what kind of visualization platform you'd like to run.  Locally, we'd reccomend using vtk, on AWS that isn't an option so we are suggesting you use itkwidgets.  vtkplotter is another option that we are demonstrating here.  We've autoselected it based upon the platform but you can override those choices if you'd like to.\n",
    "\n",
    "</div>\n",
    "\n",
    "<h2>3D Visualization Methods </h2>\n",
    "\n",
    "EM data involves high resolution reconstructions of neurons, and so visualizing them interatively in 3D is essential to understanding the data (plus it's just fun).  This requires use of more specialized plotting packages than matplotlib.  There are a few options that have different plusses and minuses that are summarized below.  We'll show you code snippets from all methods, but execute the one based upon the viz_method variable defined in the next cell.\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><h3>viz_method</h3></td>\n",
    "        <td><h3>pros</h3></td>\n",
    "        <td><h3>cons</h3></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "           vtk\n",
    "        </td>\n",
    "        <td>Fastest <br/>\n",
    "            Most features: <br/>\n",
    "            mesh coloring<br/>  \n",
    "            programatic camera control<br/>\n",
    "            programatic saving<br/>\n",
    "            extensible</td>\n",
    "        <td> Requires local installation <br/>(no AWS possible)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> itkwidgets</td>\n",
    "        <td> fastest notebook widget <br/>\n",
    "             easy screen shot <br/>\n",
    "             bug free <br/>\n",
    "             aws compatible <br/>\n",
    "        </td>\n",
    "        <td>\n",
    "        no programatic camera control<br/>\n",
    "        no advanced mesh coloring\n",
    "        </td> \n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>vtkplotter</td>\n",
    "        <td>notebook widget <br/>\n",
    "            programatic camera control <br/>\n",
    "            aws compatible</td> \n",
    "        <td>some bugs<br/>\n",
    "            slowest <br/>\n",
    "            no advanced mesh coloring\n",
    "        </td>\n",
    "     </tr>      \n",
    "    </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS\n",
    "    data_root = \"/Volumes/PNY UFD30/\"\n",
    "    viz_method = 'vtk'\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "    viz_method = 'vtk'\n",
    "elif ('amzn1' in platstring):\n",
    "    # then on AWS\n",
    "    data_root = \"/data/dynamic_brain_workshop/electron_microscopy/2019\"\n",
    "    viz_method = 'itkwidgets'\n",
    "else:\n",
    "    # then linux (default here is for Ubuntu - insert your username; your distribution may differ)\n",
    "    data_root = \"/media/$USERNAME/PNY UFD30\"\n",
    "    viz_method = 'vtk'\n",
    "# OR if you'd like to override the auto options\n",
    "# data_root = \n",
    "# viz_method = one of ['itkwidgets', 'vtk', 'vtkplotter']\n",
    "mesh_folder = os.path.join(data_root, 'meshes')\n",
    "skeleton_folder = os.path.join(data_root, 'skeletons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Import the key modules</h2>\n",
    "Our analysis workflows use a couple of special purpose packages we have developed. Here, we are going to look at the AnalysisDataLink, our package that quickly performs simple analysis queries and produces tidy Pandas dataframes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the EM specific package for querying the EM data\n",
    "from analysisdatalink.datalink_ext import AnalysisDataLinkExt as AnalysisDataLink"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Import some of our favorite modules</h2>\n",
    "Our analysis workflows makes use of many of the common scientific computing packages like Numpy and Pandas.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some of our favorite packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>set key parameters</h2>\n",
    "Every dataset has a distinct name that must be set for queries to work. The layer 2/3 dataset that we are going to use is called `pinky100` named because it is approximately 100 microns thick. \n",
    "\n",
    "It's resolution is an important parameter that we normally store in a webservice that is unavailable here at Friday Harbor, so we have to set it here.  It is 4nm x 4nm x 40nm in x,y,z.\n",
    "\n",
    "Finally, the SQL database URI sets both the location of the analysis database as well as the login info for a read-only user account. With these parameters, we can initialize a AnalysisDataLink object configured to the appropriate data.  This database has been setup specially for friday harbor so that we can access it and AWS instances can access it, so you'll need to copy it into notebooks/programs you use.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'pinky100'\n",
    "voxel_size = [4,4,40]\n",
    "sql_database_uri = 'postgresql://analysis_user:connectallthethings@swdb-em-db.crjvviai1xxh.us-west-2.rds.amazonaws.com/postgres'\n",
    "\n",
    "\n",
    "dl = AnalysisDataLink(dataset_name=dataset_name,\n",
    "                      sqlalchemy_database_uri=sql_database_uri,\n",
    "                      verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Soma_valence_v2 table</h2>\n",
    "As mentioned in the presentation, one of the key tables to query is the 'soma_valence_v2' table. \n",
    "\n",
    "This table has a point annotation of every cell with a cell body in the the volume, as well as a basic cell class annotation on that point,  as either 'e' (excitatory), 'i' (inhibitory), or 'g' (glial).  As such we use a method called 'query_cell_types' to query this table, this method provides easy ways to filter for only cells that are a particular type.\n",
    "\n",
    "Let's query excluding glia, and seperately only query for glia.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_df = dl.query_cell_types('soma_valence_v2',\n",
    "                                cell_type_exclude_filter=['g'])\n",
    "glia_df = dl.query_cell_types('soma_valence_v2',\n",
    "                              cell_type_include_filter=['g'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this table contains only neurons\n",
    "neuron_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one only glia\n",
    "glia_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Soma Valence Table Descriptions</h3>\n",
    "<table style={float:left}>\n",
    "    <tr>\n",
    "        <td><h4>column</h4></td>\n",
    "        <td><h4>description</h4></td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>id</td>\n",
    "        <td>All of the tables in the database are organized as 'annotations' on the data.  There might be several annotations on the same cell, and so the ID column uniquely identifies the annotation.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pt_position</td>\n",
    "        <td>This is the x,y,z location in voxels of the point that was annotated here as being at this cells soma location. Note, the dataset has a voxel resolution of 4,4,40 nm, and so often you want to convert this column to a nm position, which we will do below.  </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pt_supervoxel_id</td>\n",
    "        <td>You can generally ignore this column, we keep it for bookkeeping in order to make it easier to update this annotation when the segmentation changes.  </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pt_root_id</td>\n",
    "        <td>This is the unique ID of the 'root' object in the segmentation, sometimes we refer to this as a segmentation id or a cell id.  For the soma_valence_v2 table, all neurons are well segmented cells that do not have false merges or splits in them.  There are definitely segmentations errors in the glia.</td>\n",
    "    </tr>\n",
    "     \n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful function for converting a pandas data frame voxel position\n",
    "# column to a np.array of Nx3 size in nm\n",
    "def convert_to_nm(col, voxel_size=[4,4,40]):\n",
    "    return np.vstack(col.values)*voxel_size\n",
    "\n",
    "# function to plot a soma dataframe\n",
    "def plot_soma_loc(df, ax, x=0, y=1, c='r'):\n",
    "    \n",
    "    # convert the position to microns\n",
    "    pos = convert_to_nm(df['pt_position'])/1000\n",
    "    \n",
    "    # plot two dimensions as a scatterplot\n",
    "    ax.scatter(pos[:,x], pos[:,y], c=c)\n",
    "\n",
    "# get the excitatory and inhibitory soma locations\n",
    "# could do with post-query filtering...\n",
    "exc_neuron_df = dl.query_cell_types('soma_valence_v2',\n",
    "                                    cell_type_include_filter=['e'])\n",
    "inh_neuron_df = dl.query_cell_types('soma_valence_v2',\n",
    "                                    cell_type_include_filter=['i'])\n",
    "\n",
    "# make a new axis with two subplots\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2, sharex=ax1)\n",
    "\n",
    "# plot each dataframe in a different color\n",
    "plot_soma_loc(exc_neuron_df, ax1, c='r')\n",
    "plot_soma_loc(inh_neuron_df, ax1, c='b')\n",
    "\n",
    "# label some axis, make x,y scaling same\n",
    "ax1.set_xlabel('x (um)')\n",
    "ax1.set_ylabel('y (um)')\n",
    "# to keep the pia 'up'\n",
    "ax1.set_ylim(320,130)\n",
    "ax1.set_aspect('equal')\n",
    "\n",
    "# plot the same thing as x,z\n",
    "plot_soma_loc(exc_neuron_df, ax2, x=0, y=2, c='r')\n",
    "plot_soma_loc(inh_neuron_df, ax2, x=0, y=2, c='b')\n",
    "ax2.set_xlabel('x (um)')\n",
    "ax2.set_ylabel('z (um)')\n",
    "ax2.set_ylim(-10,110)\n",
    "ax2.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Coordinate System</h2>\n",
    "Below is a diagram to help you visualize the coordinate system plotted above.  \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/EM_coordinate_system.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Querying for synapses</h2>\n",
    "Let's pick out a cell ID of an excitatory neuron and then find all the synapses onto that neuron</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_id  = exc_neuron_df.iloc[0].pt_root_id\n",
    "neuron_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Now we are ready to query synapses for this neuron. Because the analysis database can, in principle, handle multiple different sources of synapses, we have to specify which synapse table we want to use. The current table holding the most up to date automated synapse detection is called `pni_synapses_i3`.\n",
    "\n",
    "Here, we specify which synapses we get back from the table by setting the `post_ids` argument to a list of IDs, which makes a query that only returns synapses whose postsynaptic id is the one selected.  You can also filter by `pre_ids` which will do the same for the pre-synaptic side. Setting this will only return synapses that are from certain neurons.  Setting both `pre_ids` and `post_ids` will return only synapses that are from the `pre_ids` onto the `post_ids`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_synapse_df = dl.query_synapses('pni_synapses_i3',\n",
    "                                    post_ids = [neuron_id])\n",
    "# lets post the shape to see how many synapses we have\n",
    "print(post_synapse_df.shape)\n",
    "# and take a peak at the whole dataframe\n",
    "post_synapse_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3> Synapse Table Descriptions</h3>\n",
    "Here's a breakdown of what each of those columns mean.\n",
    "</div>\n",
    "\n",
    "<table style={float:left}>\n",
    "    <tr>\n",
    "        <td><h4>column</h4></td>\n",
    "        <td><h4>description</h4></td>\n",
    "    </tr> \n",
    "    <tr>\n",
    "        <td>id</td>\n",
    "        <td>The ID that is specific to this synapse annotation</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pre_pt_position</td>\n",
    "        <td>a point that is in the pre-synaptic terminal of this synapse (in voxels) </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pre_pt_supervoxel_id</td>\n",
    "        <td>a bookkeeping column for the presynaptic side </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>pre_pt_root_id</td>\n",
    "        <td>the ID of the cell on the presynaptic side</td>\n",
    "    </tr>\n",
    "     <tr>\n",
    "        <td>ctr_pt_position</td>\n",
    "        <td>a point that is on the center of the synapse (in voxels)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>post_pt_position</td>\n",
    "        <td>Same as pre_pt but for the post synaptic side.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>post_pt_supervoxel_id</td>\n",
    "        <td>Same bookkeeping column as pre_pt but for the post synaptic side.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>post_pt_root_id</td>\n",
    "        <td>Same as pre_pt but for the post synaptic side</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>size</td>\n",
    "        <td>The size of the synaptic cleft in units of 4,4,40 voxels.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Each row in this table is a single synapse. You should see that the value in the post_pt_root_id column is the same for all, and equals the id you selected above. \n",
    "<h5>Note again that position columns are in voxel coordinates, just like Neuroglancer displays in the upper left corner. A single voxel has dimensions 4x4x40 nm.</h5>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets make a matrix of synapse positions for this neuron\n",
    "syn_pos_nm = convert_to_nm(post_synapse_df.ctr_pt_position)\n",
    "# and plot their positions in x,y along with the soma position as a red circle\n",
    "f ,ax =plt.subplots(1,2,figsize=(12,6))\n",
    "ax[0].scatter(syn_pos_nm[:,0]/1000, syn_pos_nm[:,1]/1000)\n",
    "\n",
    "# add the soma position as a red circle\n",
    "soma_pos = convert_to_nm(exc_neuron_df.pt_position)\n",
    "ax[0].scatter([soma_pos[0,0]/1000],[soma_pos[0,1]/1000],c='r',s=150)\n",
    "ax[0].set_aspect('equal')\n",
    "ax[0].set_xlabel('x (um)')\n",
    "ax[0].set_ylabel('y (um)')\n",
    "ax[1].scatter(syn_pos_nm[:,0]/1000, syn_pos_nm[:,2]/1000)\n",
    "\n",
    "# add the soma position as a red circle\n",
    "soma_pos = convert_to_nm(exc_neuron_df.pt_position)\n",
    "ax[1].scatter([soma_pos[0,0]/1000],[soma_pos[0,2]/1000],c='r',s=150)\n",
    "ax[1].set_aspect('equal')\n",
    "ax[1].set_xlabel('x (um)')\n",
    "ax[1].set_ylabel('z (um)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Now lets figure out which excitatory neuron makes the most synapses onto this neuron\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas groupby to count number of synapses from different neurons\n",
    "# followed by transform to label the individual synapses with \n",
    "# how many other synapses are in that connection.\n",
    "\n",
    "# transform labels all the rows in the group with the result of this function on the group\n",
    "syn_in_conn=post_synapse_df.groupby('pre_pt_root_id')['id'].transform(len)\n",
    "# save this result in a new colum\n",
    "post_synapse_df['syn_in_conn']=syn_in_conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_from_exc = post_synapse_df.pre_pt_root_id.isin(exc_neuron_df.pt_root_id.values)\n",
    "e_to_neuron_df=post_synapse_df[is_from_exc]\n",
    "e_to_neuron_df[['id',\n",
    "                'post_pt_root_id',\n",
    "                'pre_pt_root_id',\n",
    "                'syn_in_conn',\n",
    "                'ctr_pt_position',\n",
    "                'size']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Lets get the ID of the neuron that has the largest number of synapses onto this neuron\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the neuron with the most synapses\n",
    "max_input_idx = e_to_neuron_df.syn_in_conn.idxmax()\n",
    "max_input_neuron = e_to_neuron_df.loc[max_input_idx].pre_pt_root_id\n",
    "print(max_input_neuron)\n",
    "\n",
    "# print out the synapses (should be 3)\n",
    "print(e_to_neuron_df[e_to_neuron_df.pre_pt_root_id == max_input_neuron])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    <h3>Mesh visualization</h3>\n",
    "Now we can plot these synapses in 2d, but we have the detailed 3d morphology of these neurons, so why don't we look at them!\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is an EM specific package for getting meshes\n",
    "# and doing analysis on those meshes\n",
    "from meshparty import trimesh_io, trimesh_vtk\n",
    "from meshparty import skeletonize, skeleton_io, skeleton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "To access the 3d meshes of neurons, we need use a MeshMeta object, you have access to a folder with the meshes of all the neurons with cell bodies in the dataset. (i.e. anything with an pt_root_id in the soma_valence_v2 table)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = trimesh_io.MeshMeta(cv_path = 'graphene://https://swdb.dynamicannotationframework.com/segmentation/1.0/pinky100_sv16',\n",
    "                         disk_cache_path=mesh_folder,\n",
    "                         cache_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the meshes\n",
    "post_mesh = mm.mesh(seg_id = neuron_id)\n",
    "pre_mesh = mm.mesh(seg_id= max_input_neuron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "Meshes are triangular meshes, that are composed of vertices (N,3) and faces (N,3) which are indices into the vertex list\n",
    "    \n",
    "\n",
    "The Mesh class is based upon trimesh (<a href=\"https://github.com/mikedh/trimesh\"> https://github.com/mikedh/trimesh</a>), with some added features for doing graphs\n",
    "\n",
    "You can find the source code for mesh party here .. <a href=\"https://github.com/sdorkenw/MeshParty\">https://github.com/sdorkenw/MeshParty </a>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_mesh.vertices.shape, post_mesh.faces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "Below we are going to visualize things in 3d.  Different code paths  illustrate different visualization methods\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set viewer equals None so vtk option doesn't error\n",
    "viewer = None\n",
    "if viz_method == 'itkwidgets':\n",
    "    #import ITK widgets view function\n",
    "    from itkwidgets import view\n",
    "    \n",
    "    # step 1\n",
    "    # convert your actors to vtkpolydata objects\n",
    "    post_poly_data = trimesh_vtk.trimesh_to_vtk(post_mesh.vertices, post_mesh.faces, None)\n",
    "    pre_poly_data = trimesh_vtk.trimesh_to_vtk(pre_mesh.vertices, pre_mesh.faces, None)\n",
    "\n",
    "    # step 2\n",
    "    # then create a viewer with this view function\n",
    "    # pass in polydata objects, what colors you want\n",
    "    # see docstring for more options\n",
    "    viewer=view(geometries=[post_poly_data, pre_poly_data],\n",
    "                geometry_colors=['m','g'], \n",
    "                ui_collapsed=True)\n",
    "\n",
    "    # viewer controls..\n",
    "    # pinch movements:  to zoom in and out\n",
    "    # ctrl+wheel: on a mouse to do the same\n",
    "    # shift+drag: to pan\n",
    "\n",
    "elif viz_method == 'vtkplotter':\n",
    "    # import vtkplotter\n",
    "    import vtkplotter\n",
    "    # set it to use k3d as backend\n",
    "    vtkplotter.embedWindow(backend='k3d')\n",
    "    \n",
    "    # step 1\n",
    "    # convert your actors to vtkpolydata objects\n",
    "    post_poly_data = trimesh_vtk.trimesh_to_vtk(post_mesh.vertices, post_mesh.faces, None)\n",
    "    pre_poly_data = trimesh_vtk.trimesh_to_vtk(pre_mesh.vertices, pre_mesh.faces, None)\n",
    "    \n",
    "    # step 2\n",
    "    # convert those to vtkplotter Actors with color options\n",
    "    post_poly_actor = vtkplotter.Actor(post_poly_data, c='m')\n",
    "    pre_poly_actor = vtkplotter.Actor(pre_poly_data, c='g')\n",
    "    \n",
    "    # step 3\n",
    "    # Add actors to a Plotter object\n",
    "    vp = vtkplotter.Plotter(bg='w')\n",
    "    vp += post_poly_actor\n",
    "    vp += pre_poly_actor\n",
    "    \n",
    "    # step 4\n",
    "    # get a viewer\n",
    "    viewer = vp.show()\n",
    "    # pinch movements:  to zoom in and out\n",
    "    # ctrl+wheel: on a mouse to do the same\n",
    "    # right click drag: to pan\n",
    "    \n",
    "elif viz_method == 'vtk':\n",
    "\n",
    "    # Step 1\n",
    "    # Convert meshes to actors, providing color and opacity\n",
    "    # options, you can provide vertex colors to color mesh vertices\n",
    "    # however these will only be relevant for vizmethod=vtk\n",
    "    post_actor = trimesh_vtk.mesh_actor(post_mesh,\n",
    "                                    opacity=1.0,\n",
    "                                    color=(1,0,1))\n",
    "    pre_actor = trimesh_vtk.mesh_actor(pre_mesh,\n",
    "                                   opacity=1.0,\n",
    "                                   color=(0,1,0))\n",
    "    print(\"A VTK window should have popped up behind you\")\n",
    "    print(\"WARNING YOU NEED TO CLOSE IT BY PRESSING Q TO MOVE ON\")\n",
    "    # step 2\n",
    "    # render them interactively with this function\n",
    "    # passing a list of actors\n",
    "    # can optionally specify a path to save a static image\n",
    "    trimesh_vtk.render_actors([pre_actor, post_actor])\n",
    "\n",
    "    # vtk controls\n",
    "    # pinch movements:  to zoom in and out\n",
    "    # ctrl+wheel: on a mouse to do the same\n",
    "    # shift+drag: to pan\n",
    "    # mouse over + f: to zoom to where you point and recenter camera there\n",
    "    # w: wireframe visualization\n",
    "    # s: surface visualization\n",
    "    # q: to exit visualization\n",
    "    \n",
    "# to display widget if doing itkwidgets or vtkplotter\n",
    "viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in vtk and vtkplotter there is more camera control\n",
    "# so this is how you would automatically center the camera\n",
    "# on the first synapse between these neurons\n",
    "max_synapses = e_to_neuron_df[e_to_neuron_df.pre_pt_root_id == max_input_neuron]\n",
    "\n",
    "# get the location of the first synapse (change 0 to 1 or 2 to look at others)\n",
    "syn_pos =convert_to_nm(max_synapses.iloc[[0]].ctr_pt_position)\n",
    "\n",
    "# create a camera object pointed at the synapse\n",
    "camera = trimesh_vtk.oriented_camera(syn_pos, backoff=20)\n",
    "\n",
    "if viz_method == 'vtk':\n",
    "    print(\"A VTK window should have popped up behind you\")\n",
    "    print(\"WARNING YOU NEED TO CLOSE IT BY PRESSING Q TO MOVE ON\")\n",
    "    # pass the camera to the render_actors function to control camera\n",
    "    trimesh_vtk.render_actors([post_actor, pre_actor], camera=camera)\n",
    "\n",
    "elif viz_method == 'vtkplotter':\n",
    "    # convert this camera to a k3d camera matrix\n",
    "    kcamera = np.concatenate([camera.GetPosition(),\n",
    "                              camera.GetFocalPoint(),\n",
    "                              camera.GetViewUp()])\n",
    "    # this will immediately move the camera of the viewer above\n",
    "    viewer.camera = kcamera\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "How far apart are these synapses?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one way is to measure it in euclidean distance\n",
    "max_syn_pos = convert_to_nm(max_synapses.ctr_pt_position)\n",
    "\n",
    "# calculate delta from one synapse to the next in the list\n",
    "dv = np.diff(max_syn_pos, axis=0)\n",
    "\n",
    "# convert this to a euclidean distance\n",
    "euc_dist = np.linalg.norm(dv, axis=1)\n",
    "\n",
    "# print it in microns\n",
    "# returns distance from synapse 1>2 and 2>3\n",
    "print(euc_dist/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# another is to try to measure the shortest path along the mesh\n",
    "# first we map the synapse to its closest mesh point using a kdtree\n",
    "ds_post, close_inds_post = post_mesh.kdtree.query(max_syn_pos)\n",
    "ds_pre, close_inds_pre = pre_mesh.kdtree.query(max_syn_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can see the mapping distances are quite small\n",
    "# this is good.. means the synapses are near the edge of the mesh\n",
    "# but it also gives us the vertex index\n",
    "print(ds_post)\n",
    "print(ds_pre)\n",
    "print(close_inds_post)\n",
    "print(close_inds_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dijkstra lets us calculate the shortest path along graph to points\n",
    "ds_short_post, pred_post = sparse.csgraph.dijkstra(post_mesh.csgraph,\n",
    "                                         directed=False,\n",
    "                                         indices=close_inds_post[0], \n",
    "                                         return_predecessors=True)\n",
    "\n",
    "ds_short_pre, pred_pre = sparse.csgraph.dijkstra(pre_mesh.csgraph,\n",
    "                                         directed=False,\n",
    "                                         indices=close_inds_pre[0], \n",
    "                                         return_predecessors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the answer in microns\n",
    "# these are the distances from synapse 1 to synapse 2\n",
    "# along the pre-synaptic mesh and along the post-synaptic mesh\n",
    "print(ds_short_pre[close_inds_pre[1]]/1000,\n",
    "      ds_short_post[close_inds_post[1]]/1000)\n",
    "\n",
    "# and from synapse 1 to synapse 3\n",
    "print(ds_short_pre[close_inds_pre[2]]/1000,\n",
    "      ds_short_post[close_inds_post[2]]/1000)\n",
    "\n",
    "# you can see that synapse 1 and 2 are also close along the mesh\n",
    "# but synapse 1 and 3 are much further than the euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to visualize these paths we need to convert the output\n",
    "# convert the predecessors array to a set of edges\n",
    "# lets look at from synapse 1 to 3\n",
    "# starting at the other synapse\n",
    "path_post = skeletonize.utils.path_from_predecessors(pred_post,\n",
    "                                                     close_inds_post[2])\n",
    "edges_post = skeletonize.utils.paths_to_edges([path_post])\n",
    "\n",
    "# do the same for the pre-synaptic side\n",
    "path_pre = skeletonize.utils.path_from_predecessors(pred_pre,\n",
    "                                                    close_inds_pre[2])\n",
    "edges_pre = skeletonize.utils.paths_to_edges([path_pre])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from itkwidgets import view\n",
    "# get a reduced set of vertices and reindexed edges\n",
    "# for these paths\n",
    "post_sk_verts, post_sk_edges = trimesh_vtk.remove_unused_verts(post_mesh.vertices,\n",
    "                                                               edges_post)\n",
    "\n",
    "# do the same for the other side\n",
    "pre_sk_verts, pre_sk_edges = trimesh_vtk.remove_unused_verts(pre_mesh.vertices,\n",
    "                                                             edges_pre)\n",
    "\n",
    "\n",
    "if viz_method == 'itkwidgets':\n",
    "\n",
    "    sk_pre_poly = trimesh_vtk.graph_to_vtk(pre_sk_verts,\n",
    "                                           pre_sk_edges)\n",
    "    sk_post_poly = trimesh_vtk.graph_to_vtk(post_sk_verts,\n",
    "                                            post_sk_edges)\n",
    "\n",
    "    viewer = view(geometries=[pre_poly_data, post_poly_data,\n",
    "                              sk_pre_poly, sk_post_poly],\n",
    "                  geometry_colors=['g', 'm', 'g', 'm'],\n",
    "                  geometry_opacities=[.05, .05, 1.0, 1.0],\n",
    "                  ui_collapsed=True)\n",
    "elif viz_method == 'vtk':\n",
    "    \n",
    "    sk_pre = skeleton.Skeleton(pre_sk_verts, pre_sk_edges)\n",
    "    sk_post = skeleton.Skeleton(post_sk_verts, post_sk_edges)\n",
    "    # make actors with skeleton specific function\n",
    "    sk_post_actor = trimesh_vtk.skeleton_actor(sk_post,\n",
    "                                               line_width=5,\n",
    "                                               color=(.5,0,.5))\n",
    "    sk_pre_actor = trimesh_vtk.skeleton_actor(sk_pre,\n",
    "                                              line_width=5,\n",
    "                                              color=(0,.5,0))\n",
    "    \n",
    "    # make the meshes as before, but make them transparent\n",
    "    post_actor = trimesh_vtk.mesh_actor(post_mesh,\n",
    "                                        opacity=0.1,\n",
    "                                        color=(1,0,1))\n",
    "    pre_actor = trimesh_vtk.mesh_actor(pre_mesh,\n",
    "                                       opacity=0.1,\n",
    "                                       color=(0,1,0))\n",
    "    # render your actors\n",
    "    trimesh_vtk.render_actors([pre_actor,\n",
    "                               post_actor,\n",
    "                               sk_post_actor,\n",
    "                               sk_pre_actor])\n",
    "elif viz_method == 'vtkplotter':\n",
    "    import vtkplotter\n",
    "    # convert meshes to polydata objects\n",
    "    post_poly_data = trimesh_vtk.trimesh_to_vtk(post_mesh.vertices,\n",
    "                                                post_mesh.faces, None)\n",
    "    pre_poly_data = trimesh_vtk.trimesh_to_vtk(pre_mesh.vertices,\n",
    "                                               pre_mesh.faces, None)\n",
    "    \n",
    "    \n",
    "    # make a vtkPolyData object from them\n",
    "    sk_pre_poly = trimesh_vtk.graph_to_vtk(pre_sk_verts,\n",
    "                                           pre_sk_edges)\n",
    "    sk_post_poly = trimesh_vtk.graph_to_vtk(post_sk_verts,\n",
    "                                            post_sk_edges)\n",
    "    \n",
    "    # convert those to vtkplotter Actors with color options\n",
    "    sk_post_actor = vtkplotter.Actor(sk_pre_poly, c='m')\n",
    "    sk_pre_actor = vtkplotter.Actor(sk_post_poly, c='g')\n",
    "    \n",
    "    # convert the meshes, making them transparent\n",
    "    post_poly_actor = vtkplotter.Actor(post_poly_data,\n",
    "                                       c='m',\n",
    "                                       alpha=.05)\n",
    "    pre_poly_actor = vtkplotter.Actor(pre_poly_data,\n",
    "                                      c='g',\n",
    "                                      alpha=.05)\n",
    "    \n",
    "    # Add actors to a Plotter object\n",
    "    vp = vtkplotter.Plotter(bg='w')\n",
    "    vp += post_poly_actor\n",
    "    vp += pre_poly_actor\n",
    "    vp += sk_post_actor\n",
    "    vp += sk_pre_actor\n",
    "    \n",
    "    # step 4\n",
    "    # get a viewer\n",
    "    viewer = vp.show()\n",
    "viewer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see something like this\n",
    "<img src=\"../resources/EM_neuron_distance.png\">  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excecise idea... what is the difference in the shortest path from the soma to these two synapses?\n",
    "# project idea... what is the distribution of conduction delays for multi synaptic synapses in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    <h3> Visualizing synapses </h3>\n",
    "Now what if we just want to see the synapse locations without the mesh of the other side\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# synapse sizes tend to distributed widely\n",
    "# so we are going to color and size them proportional to the log\n",
    "syn_color = np.log(post_synapse_df['size'].values)\n",
    "syn_size = 100*np.log(post_synapse_df['size'].values)\n",
    "\n",
    "# this will produce spheres at each point with sizes in nm\n",
    "# and color values that are mapped through a colormap\n",
    "# in VTK only you can pass explicit colors as well\n",
    "syn_actor = trimesh_vtk.point_cloud_actor(syn_pos_nm, size=syn_size, color=syn_color)\n",
    "\n",
    "if viz_method == 'vtk':\n",
    "    print('remember the window pops up behind')\n",
    "    trimesh_vtk.render_actors([post_actor, syn_actor])\n",
    "if viz_method == 'itkwidgets':\n",
    "    syn_pd = syn_actor.GetMapper().GetInput()\n",
    "    viewer = view(geometries=[post_poly_data, syn_pd],\n",
    "                  geometry_colors=['m','g'],\n",
    "                  ui_collapsed=True)\n",
    "if viz_method == 'vtkplotter':\n",
    "    import vtkplotter\n",
    "    syn_pd = syn_actor.GetMapper().GetInput()\n",
    "    syn_actor =  vtkplotter.Actor(syn_pd)\n",
    "    post_poly_data = trimesh_vtk.trimesh_to_vtk(post_mesh.vertices,\n",
    "                                                post_mesh.faces, None)\n",
    "    post_poly_actor = vtkplotter.Actor(post_poly_data,\n",
    "                                       c='m',\n",
    "                                       alpha=1.0)\n",
    "    vp = vtkplotter.Plotter(bg='w')\n",
    "    vp += post_poly_actor\n",
    "    vp += syn_actor\n",
    "    \n",
    "    # step 4\n",
    "    # get a viewer\n",
    "    viewer = vp.show()\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Skeletons</h3>\n",
    "In addition to meshes, we have precalculated skeleton representations of each neuron, lets load those skeletons and visualize them\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can find them in the skeleton folder\n",
    "pre_sk_file = os.path.join(skeleton_folder, f'{max_input_neuron}.h5')\n",
    "post_sk_file = os.path.join(skeleton_folder, f'{neuron_id}.h5')\n",
    "\n",
    "# this is how you read them in\n",
    "sk_pre = skeleton_io.read_skeleton_h5(pre_sk_file)\n",
    "sk_post = skeleton_io.read_skeleton_h5(post_sk_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a quick visualization\n",
    "sk_pre_actor = trimesh_vtk.skeleton_actor(sk_pre, color=(1,0,0))\n",
    "sk_post_actor = trimesh_vtk.skeleton_actor(sk_post, color=(0,1,0))\n",
    "if viz_method == 'vtk':\n",
    "    print('remember the window pops up behind')\n",
    "    trimesh_vtk.render_actors([sk_pre_actor, sk_post_actor])\n",
    "if viz_method == 'itkwidgets':\n",
    "    sk_pre_pd = sk_pre_actor.GetMapper().GetInput()\n",
    "    sk_post_pd = sk_post_actor.GetMapper().GetInput()\n",
    "    viewer = view(geometries=[sk_post_pd, sk_pre_pd],\n",
    "                  geometry_colors=['m', 'g'],\n",
    "                  ui_collapsed=True)\n",
    "if viz_method == 'vtkplotter':\n",
    "    sk_pre_pd = sk_pre_actor.GetMapper().GetInput()\n",
    "    sk_post_pd = sk_post_actor.GetMapper().GetInput()\n",
    "    \n",
    "\n",
    "    sk_post_a = vtkplotter.Actor(sk_post_pd,\n",
    "                                 c='m',\n",
    "                                 alpha=1.0)\n",
    "    sk_pre_a = vtkplotter.Actor(sk_pre_pd,\n",
    "                                c='g',\n",
    "                                alpha=1.0)\n",
    "    vp = vtkplotter.Plotter(bg='w')\n",
    "    vp += sk_post_a\n",
    "    vp += sk_pre_a\n",
    "    \n",
    "    # step 4\n",
    "    # get a viewer\n",
    "    print('vtkplotter has some bugs here.. not sure why')\n",
    "    viewer = vp.show()\n",
    "viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "These skeleton classes come with a variety of useful features, such as a csgraph so you can use scipy.sparse.csgraph functions on the skeleton to find distances.  Also, they have a radius with every node in vertex_properties, and a mapping between mesh vertices and skeleton vertices.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
