{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Brain Observatory - Visual Behavior </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">Monday, August 26, 2018</h3> \n",
    "\n",
    "<img src=\"../resources/visual_behavior_experiment.png\" height=\"400\" width=\"1200\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the Visual Behavior Brain Observatory dataset. This dataset uses 2-photon calcium imaging (also called optical physiology or ophys) to measure neural activity in mice performing a visual change detection task. One aim of this dataset is to ask: how is sensory coding influenced by expectation, engagement, and experience?\n",
    "\n",
    "The change detection task consists of a series of image presentations. Each image flash is 250ms followed by 500ms of gray screen. The task for the mouse is to lick in a 750ms response window following a change in image identity. On each trial, a change time is scheduled. On go trials, a change in image identity occurs. On catch trials, no image change occurs (aka 'sham change'), and we measure false alarm rates in the same 750ms response window. Correct responses are rewarded and licks outside the response window result in a timeout.\n",
    "\n",
    "There are 8 natural scene images shown in each behavioral session. Mice learn the task with one set of 8 natural scenes which become highly familiar with experience. During the imaging phase of the experiment, mice perform the task with the familiar image set, as well as another set of 8 images that are experienced for the first time under the microscope. This allows us to ask how training history and visual experience infuence sensory responses. \n",
    "\n",
    "There are 2 types of sessions during the imaging portion of the experiment - active behavior and passive viewing. During the passive viewing sessions, the task is run in open loop mode with the lick spout retracted, after the mouse has been give its daily allocation of water. This allows us to ask how representations differ when the mouse is actively engaged in the task and motivated to earn water rewards compared to when it is sated and not receiving reward feedback.\n",
    "\n",
    "During imaging sessions, 5% of non-change image flashes are randomly omitted from the otherwise regular sequence of stimulus presentations. This allows us to ask whether expectation signals are present in the visual cortex. \n",
    "\n",
    "The dataset consists of recordings from excitatory (Slc17a7-IRES2-Cre;CaMK2-tTA;Ai93(GCaMP6f)) and VIP inhibitory (VIP-IRES-Cre;Ai162(GCaMP6f)) neurons in V1. Excitatory cells were sampled at 2 depths: 175um (L2/3) and 375um (L5). VIP cells were sampled at 175um depth.\n",
    "\n",
    "In this notebook, we will describe the core components of each experimental session and the tools for accessing and analyzing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "\n",
    "<p>Let's get started\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need these libraries for computation & data manipulation\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib is a standard python visualization package\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# seaborn is another library for statistical data visualization\n",
    "# seaborn style & context settings make plots pretty & legible\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'lines.markeredgewidth': 2})\n",
    "sns.set_style('white')\n",
    "sns.set_palette('deep');\n",
    "\n",
    "# Import allensdk modules for loading and interacting with the data\n",
    "from allensdk.brain_observatory.behavior.swdb import behavior_project_cache as bpc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The first thing we will do is use the `allensdk` to load a cache for the visual behavior dataset, which contains a manifest describing the dimensions of the dataset and methods for loading the data from particular sessions. You can inspect the manifest contained in the cache to identify experiments of interest and their metadata. \n",
    "\n",
    "<p>Make sure you have access to the `visual_behavior_cache.json` file, which tells the cache object where to find the data. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS paths\n",
    "\n",
    "# Mac/Linux paths\n",
    "# cache_json = {'manifest_path': '/allen/programs/braintv/workgroups/nc-ophys/visual_behavior/SWDB_2019/visual_behavior_data_manifest.csv',\n",
    "#               'nwb_base_dir': '/allen/programs/braintv/workgroups/nc-ophys/visual_behavior/SWDB_2019/nwb_files',\n",
    "#               'analysis_files_base_dir': '/allen/programs/braintv/workgroups/nc-ophys/visual_behavior/SWDB_2019/analysis_files',\n",
    "#               'analysis_files_metadata_path': '/allen/programs/braintv/workgroups/nc-ophys/visual_behavior/SWDB_2019/analysis_files_metadata.json'\n",
    "# }\n",
    "# Windows paths\n",
    "cache_json = {'manifest_path': r'\\\\allen\\programs\\braintv\\workgroups\\nc-ophys\\visual_behavior\\SWDB_2019\\visual_behavior_data_manifest.csv',\n",
    "              'nwb_base_dir': r'\\\\allen\\programs\\braintv\\workgroups\\nc-ophys\\visual_behavior\\SWDB_2019\\nwb_files',\n",
    "              'analysis_files_base_dir': r'\\\\allen\\programs\\braintv\\workgroups\\nc-ophys\\visual_behavior\\SWDB_2019\\analysis_files',\n",
    "              'analysis_files_metadata_path': r'\\\\allen\\programs\\braintv\\workgroups\\nc-ophys\\visual_behavior\\SWDB_2019\\analysis_files_metadata.json'\n",
    "             }\n",
    "\n",
    "cache = bpc.BehaviorProjectCache(cache_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.1:**  Get information about what's in the dataset \n",
    "\n",
    "<p>Read in 'visual_behavior_data_manifest.csv' using the cache object and explore the columns to see the available visual areas, cre lines, and session types. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the manifest of all experiment sessions for this dataset\n",
    "manifest = cache.manifest\n",
    "manifest.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the dimensions of this dataset? \n",
    "print('targeted structures:', manifest.targeted_structure.unique())\n",
    "print('\\ncre_lines:', manifest.full_genotype.unique())\n",
    "print('\\nstage_types:', manifest.stage_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.2:**  Everyone gets an experiment! \n",
    "\n",
    "<p>Get your experiment ID and assign it to a variable called `experiment_id`\n",
    "\n",
    "<p>What is the `targeted_structure`, 'imaging_dpeth', `full_genotype`, and `stage_name` for your `experiment_id`? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random experiment\n",
    "experiment_index = np.random.random_integers(low=0,high=len(manifest.ophys_experiment_id.values))\n",
    "experiment_id = manifest.ophys_experiment_id.values[experiment_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata for this experiment from the manifest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 1.3:**  What is in an experiment container? \n",
    "\n",
    "<p>The experiment container describes a set of imaging sessions performed at the same location (targeted structure and imaging depth) in the same mouse that targets the same set of cells. All the sessions in an experiment container have a common `experiment_container_id`.\n",
    "\n",
    "<p>Get a the `experiment_container_id` for your `experiment_id` and find out what other sessions were recorded at that same location. \n",
    "\n",
    "<p>Do all experiment containers have the same number of sessions associated with them? Hint: use pandas groupby\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the container ID for this experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what other sessions are in this container?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of sessions in each container\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Behavior OPhys Session object</h2>\n",
    "<p>The BehaviorOphysSession class in allensdk.brain_observatory.behavior.behavior_ophys_session provides an interface to all of the data for a single experimental session from the Visual Behavior pipeline, aligned to a common time clock.\n",
    "\n",
    "<p>We package each session's data into a Neurodata Without Borders 2.0 (NWB) file. The BehaviorOphysSession will load data from the NWB file for a given session.\n",
    "    \n",
    "<p>You can load a BehaviorOphysSession object easily using the 'get_session' method of the cache object. \n",
    "\n",
    "<p>Use help to see what functions are contained in the session object. \n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a session from the cache\n",
    "session = cache.get_session(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.1:**  What is an experiment session? \n",
    "\n",
    "<p>Use tab completion to see what is in the dataset object for an experiment session\n",
    "\n",
    "<p>What is in the `metadata` attribute? What is in the 'task_parameters' attribute?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session task parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Optical physiology data - max projection, roi masks, and fluorescence traces</h2>\n",
    "\n",
    "<p>Let's use the session object to access neuron fluorescence timeseries, roi masks, and metadata. An ROI mask is used to define the boundary of each cell in the flourescence data. The timeseries extracted from each ROI is one cell's activity.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.1: max intensity projection and ROI masks** \n",
    "    \n",
    "<p>Get the maximum intensity projection image using the `max_projection` attribute for your dataset and display it. \n",
    "    \n",
    "<p>Get the 'segmentation_mask_image' and display it next to the max projection. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the max intensity projection and the segmentation mask\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.2: Get dF/F traces and ophys timestamps**\n",
    "\n",
    "<p>Get the fluorescence traces and ophys timestamps. How are they formatted?\n",
    "\n",
    "<p>`dff_traces` is a dataframe with 'cell_specimen_id' as the index and 'cell_roi_id' and 'dff' as columns. \n",
    "    \n",
    "<p>'cell_roi_id' is the unique identifier for each cell within a session. 'cell_specimen_id' is the unified cell identifier after cells are matched across sessions within a container. Cells found in multiple sessions will have the same 'cell_specimen_id' in all the sessions in which they were found.  \n",
    "    \n",
    "<p>the 'dff' column contains the baseline normalized fluorescence traces, also called dF/F traces, for each cell in the session. \n",
    "    \n",
    "<p>`timestamps_ophys` is an array of timestamps for each 2P imaging frame. \n",
    "    \n",
    "<p>Check that the length of one of the dF/F traces is the same length as the ophys timestamps.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get traces and timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of traces and timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of one cell's trace\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.3: Plot the dF/F trace for a cell**\n",
    "\n",
    "<p>Plot the dF/F trace for one cell by indexing into the `dff_traces` array. Use `timestamps_ophys` to plot the y_axis in seconds. \n",
    "    \n",
    "<p>Try plotting the trace for a few different cells.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dF/F trace for one cell using ophys timestamps for x-axis values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 2.4: Plot a heatmap of all cell traces in this session**\n",
    "\n",
    "<p>Extract the dff_traces from the dataframe into an array. What is the shape?\n",
    "\n",
    "<p>Use the matplotlib plotting function pcolormesh to plot the matrix as a heatmap. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dff_traces into an array of cells x timepoints\n",
    "dff_traces_array = np.vstack(dff_traces.dff.values)\n",
    "print('shape of dff_traces_array:',dff_traces_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heatmap of all traces \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "cax = ax.pcolormesh(dff_traces_array, cmap='magma', vmin=0, vmax=np.percentile(dff_traces_array, 99))\n",
    "ax.set_yticks(np.arange(0, len(dff_traces_array)), 10);\n",
    "ax.set_ylabel('cells')\n",
    "ax.set_xlabel('time (sec)')\n",
    "ax.set_xticks(np.arange(0, len(timestamps_ophys), 600*31));\n",
    "ax.set_xticklabels(np.arange(0, timestamps_ophys[-1], 600));\n",
    "cb = plt.colorbar(cax, pad=0.015, label='dF/F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Behavior timeseries and events - running, licks, and rewards </h2>\n",
    "<p>As the mouse performs the behavioral task, it is free to run on a disk. The task is a go/no-go style task with licking as the behavioral response. When a mouse correctly licks the water spout, a reward is delivered. \n",
    "\n",
    "<p>Running, licks and rewards are measured at the stimulus frame display rate and share timestamps with the stimulus. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.1: Get running speed trace and timestamps** \n",
    "\n",
    "<p>Get the `running_speed` attribute of the dataset object. What does it contain? \n",
    "\n",
    "<p>Runnning speed shares timestamps with the visual stimulus. Compare the values of running timestamps from  `running_speed` with the values in the dataset attribute `stimulus_timestamps`. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get running speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what are the values of running speed timestamps?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the values of stimulus timestamps?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.2: Plot running speed**\n",
    "\n",
    "<p>Plot the values for running speed with time in seconds on the x-axis. \n",
    "    \n",
    "<p>Running speed is measured in cm/s. Label the axes appropriately.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running speed with timestamps on x-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.4: Rewards and licks**\n",
    "    \n",
    "<p>Get the 'rewards' attribute of the session object. How is it formatted? \n",
    "\n",
    "<p>Get the 'licks' attribute of the session object. How is it formatted? \n",
    "\n",
    "<p>What is the relationship between running, licking and rewards? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about licks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 3.5: Plot licking, reward times, and running trace on the same figure**\n",
    "    \n",
    "<p>1) Plot `running_speed` as above, but set xlims to focus on a 30 second portion of the behavior session, from x=600 to x=630. \n",
    "\n",
    "<p>2) Plot `rewards` as points (not a line), at y = -10. Note that `rewards` is a dataframe, with timestamps as the index. Use the values of the index to get the times of all rewards to plot along the x-axis.\n",
    "\n",
    "<p>Hint: You will need to create an array of len(session.rewards.index.values) filled with -10 to use as y-axis values to plot. np.repeat() is a convenient function for this.\n",
    "\n",
    "<p>3) Plot `licking` times using plt.vlines() with ymin=-10 and ymax=-5. \n",
    "\n",
    "<p>4) Bonus: Create a legend to label licks, rewards, and running. \n",
    "\n",
    "<p>What is the relationship between running, licking and rewards? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running speed, rewards, and licks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Visual stimuli </h2>\n",
    "    \n",
    "<p>The timing of visual stimui can be accessed through the 'stimulus_presentations' table. This includes the timing of omitted stimuli - in other words, the time where the image would have been presented if it were not omitted.  \n",
    "    \n",
    "<p>The images shown during the session are included in the 'stimulus_template'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 4.1: Get the stimulus table**\n",
    "\n",
    "<p>Get the `stimulus_presentations` attribute to identify the times of stimulus presentations. How many stimulus flashes were there? \n",
    "\n",
    "<p>What other data is included for each stimulus flash in this table? What could it be used for?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stimulus presentations table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many stimulus presentations were there? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the keys of the stimulus presentations table?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 4.2: Plot visual stimulus presentations with behavior events**\n",
    "\n",
    "<p>1) Copy and paste your code from Task 3.5\n",
    "\n",
    "<p>2) Plot stimulus presentations using the `start_time` and `stop_time` columns with plt.axvspan(). Set alpha=0.3 & facecolor='gray'.\n",
    "\n",
    "<p>Hint: Loop through each row of the stimulus table using the pandas method 'iterrows' to plot all stimulus flashes\n",
    "    \n",
    "<p>3) Bonus: Plot stimulus presentations corresponding to image changes using the 'changes' column. Set facecolor='blue' to distinguish from non-change flashes. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running, rewards, licks and stimuli using axvspan to delineate periods where a stimulus was shown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 4.3: Get visual stimulus templates**\n",
    "\n",
    "<p>Get the `stimulus_templates` from the session object. What is the shape?\n",
    "\n",
    "<p>The first dimension of `stimulus_templates` corresponds to the `image_index` in `stimulus_presentations`.\n",
    "    \n",
    "<p>Plot an image from 'stimulus_templates' using its 'image_index'. Show the name of the image in the title by finding the 'image_name' that corresponds to that 'image_index' in the 'stimulus_presentations' table.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stimulus templates and print the shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a stimulus using its image index\n",
    "\n",
    "# show the image name for that image index using the stimulus presentations table and show it in the title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Behavior trials data</h2>\n",
    "    \n",
    "<p>The `trials` dataframe organizes behavior events (including licking and rewards), stimulus information (what stimulus was shown before and after the scheduled change time) and metadata (such as whether the trial was a 'go' trial or a 'catch' trial) for each behavioral trial. \n",
    "\n",
    "<p>This structure is convenient for data exploration and analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 5.1: Explore the trials table**\n",
    "\n",
    "<p>1) Get the `trials` attribute of the `session` object. What are the columns of this dataframe? What are the rows?\n",
    "\n",
    "<p>2) How many go trials were there? How many catch trials? What is the ratio of go to catch trials?\n",
    "\n",
    "<p>3) What images were shown in this behavior session? Use the pandas 'unique' method to get the unique images from the trials table. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the trials table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many go trials were there? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many catch trials were there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what images were shown? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 5.2: Get the hit and false alarm rates for this session**\n",
    "\n",
    "<p>The hit rate is the fraction of go trials with a lick in the reward window\n",
    "    \n",
    "<p>The false alarm rate is the fraction of catch trials with a lick in the reward window\n",
    "\n",
    "<p>1) Select all the 'go' trials by filtering the dataframe by `go`. Get the fraction of 'go' trials where 'hit' = True. \n",
    "\n",
    "<p>2) Repeat for 'catch' trials.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the hit rate for go trials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the false alarm rate for catch trials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 5.3: Plot hit rate across images for go trials**\n",
    "\n",
    "<p>1) Loop through the image names in `session.trials.change_image_name.unique()`\n",
    "\n",
    "<p>2) Quantify the fraction of 'go' trials with a `hit` for each image\n",
    "\n",
    "<p>3) Sort the hit rates using np.sort() and plot the sorted hit rate by image\n",
    "    \n",
    "<p>4) Get the sorted indices using np.argsort() and apply this ordering to the image names to plot on the x-axis\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the hit rate for each image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the hit rates in ascending order and sort the image labels in the same order\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot hit rate by image with image names on the x-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 5.4: Plot a lick raster**\n",
    "\n",
    "<p>Provide the `trials` dataframe to the function below to plot a lick raster.\n",
    "\n",
    "<p>Is the mouse performing the task consistently across the whole session?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lick_raster(trials):\n",
    "    trials = trials[trials.aborted==False]\n",
    "    trials = trials.reset_index()\n",
    "    fig,ax = plt.subplots(figsize=(5,10))\n",
    "    for trial_index, trial_data in trials.iterrows(): \n",
    "        # get times relative to change time\n",
    "        lick_times = [(t - trial_data.change_time) for t in trial_data.lick_times]\n",
    "        reward_time = [(t - trial_data.change_time) for t in [trial_data.reward_time]]\n",
    "        # plot reward times\n",
    "        if len(reward_time) > 0:\n",
    "            ax.plot(reward_time[0], trial_index + 0.5, '.', color='b', label='reward', markersize=6)\n",
    "        # plot lick times\n",
    "        ax.vlines(lick_times, trial_index, trial_index + 1, color='k', linewidth=1)\n",
    "        # put a line at the change time\n",
    "        ax.vlines(0, trial_index, trial_index + 1, color=[.5, .5, .5], linewidth=1)\n",
    "    # gray bar for response window\n",
    "    ax.axvspan(0.15, 0.75, facecolor='gray', alpha=.3, edgecolor='none')\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim(0, len(trials))\n",
    "    ax.set_xlim([-1, 4])\n",
    "    ax.set_ylabel('trials')\n",
    "    ax.set_xlabel('time (sec)')\n",
    "    ax.set_title('lick raster')\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the lick raster for this session using the provided function\n",
    "make_lick_raster(session.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Trial Response and Flash Response dataframes organize cell responses by behavior trials and stimulus flashes </h2>\n",
    "    \n",
    "<p> These two dataframes do the work of temporal alignment for you to create a convenient data structure for analysis. \n",
    "  \n",
    "<p> The `trial_response_df` extracts cell responses for each behavioral trial in a [-4,8] second window around the change time.\n",
    "    \n",
    "<p> The `flash_response_df` extracts cell responses for each stimulus presentation in a [-0.5, 0.75] second window around each flash. \n",
    "    \n",
    "<p> Both dataframes take the mean response for each cell in a 500ms window after the change time for trials, or after the stimulus onset time for stimulus presentations.\n",
    "    \n",
    "<p> These dataframes also include a p_value comparing the response for each cell on each trial to a shuffled distribution from the spontaneous activity epochs. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.1:** Load and explore the Trial Response Dataframe. \n",
    "\n",
    "<p>1) Get the `trial_response_df` attribute of the session object. What are the columns? What are the rows? What is different than the `trials` table? \n",
    "    \n",
    "<p>The `dff_trace` column contains a portion of each cell's dF/F trace from 4 seconds before the `change_time` to 8 seconds after the 'change_time' for each trial. There are also `dff_trace_timestamps` for the same window. \n",
    "\n",
    "<p> For each trial, the `mean_response` of each cell is computed for a 500ms window after the `change_time`.\n",
    "\n",
    "<p>2) Assign `trial_response_df` to a variable named `tr` for convenient use in later exercises.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the trial response dataframe and assign it to 'tr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is in the trial response dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.2:** Plot the population average trace for go trials. \n",
    "\n",
    "<p>Select go trials from the 'trial_response_df', take the mean across all cells, all trials, and plot it\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across all cells for go trials\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.3: Plot the population response across cells for one change trial**\n",
    "\n",
    "<p>1) Select one 'trial_id' where 'go' = True and filter the trial_response_df to get the data for just that trial. How many rows are in this subset of data? Is it the same length as the number of unique cells?\n",
    "\n",
    "<p>2) Get the 'mean_response' for all cells,  sort in order of response magnitude and plot it. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for all cells for a single go trial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean response across cells for this trial, with cells on x-axis and mean dF/F on y-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.4: Explore the flash response dataframe**\n",
    "\n",
    "<p>What is in the `flash_response_df` attribute of the session object? What are the columns? What are the rows?  How is it different from the `stimulus_presentations` table?\n",
    "\n",
    "<p>The`flash_response_df` contains the cell responses for individual stimulus presentations, aka flashes. It contains the `mean_response` of every cell in a 500ms window after every stimulus onset, for all stimulus presentations during the behavior session.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the flash response dataframe and assign it to 'fr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats in the flash response dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.5: Plot the mean response to each image across all flashes**\n",
    "\n",
    "<p>1) Select one image and plot the mean response across all cells using the 'dff_trace' column. Put the 'image_name' in the title. \n",
    "    \n",
    "<p>2) Plot the mean response to all images on the same figure. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across all cells for one image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across cells separately for each image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p>**Task 6.6: Plot one cell's response to each image across all flashes**\n",
    "    \n",
    "<p>Create the same plot for a single cell rather than the whole population. \n",
    "    \n",
    "<p>What does it look like for different cells?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across images for one cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "visual_behavior_sdk",
   "language": "python",
   "name": "visual_behavior_sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
