{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Brain Observatory - Visual Behavior </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">Monday, August 26, 2019</h3> \n",
    "\n",
    "<img src=\"../resources/visual_behavior_experiment.png\" height=\"400\" width=\"1200\">  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will introduce you to the Visual Behavior Brain Observatory dataset. This dataset uses 2-photon calcium imaging (also called optical physiology or ophys) to measure neural activity in mice performing a visual change detection task. One aim of this dataset is to ask: how is sensory coding influenced by expectation, engagement, and experience?\n",
    "\n",
    "The change detection task consists of a series of image presentations. Each image flash is 250ms followed by 500ms of gray screen. The task for the mouse is to lick in a 750ms response window following a change in image identity. On each trial, a change time is scheduled. On go trials, a change in image identity occurs. On catch trials, no image change occurs (aka 'sham change'), and we measure false alarm rates in the same 750ms response window. Correct responses are rewarded and licks outside the response window result in a timeout.\n",
    "\n",
    "There are 8 natural scene images shown in each behavioral session. Mice learn the task with one set of 8 natural scenes which become highly familiar with experience. During the imaging phase of the experiment, mice perform the task with the familiar image set, as well as another set of 8 images that are experienced for the first time under the microscope. This allows us to ask how training history and visual experience infuence sensory responses. \n",
    "\n",
    "There are 2 types of sessions during the imaging portion of the experiment - active behavior and passive viewing. During the passive viewing sessions, the task is run in open loop mode with the lick spout retracted, after the mouse has been give its daily allocation of water. This allows us to ask how representations differ when the mouse is actively engaged in the task and motivated to earn water rewards compared to when it is sated and not receiving reward feedback.\n",
    "\n",
    "During imaging sessions, 5% of non-change image flashes are randomly omitted from the otherwise regular sequence of stimulus presentations. This allows us to ask whether expectation signals are present in the visual cortex. \n",
    "\n",
    "The dataset consists of recordings from excitatory (Slc17a7-IRES2-Cre;CaMK2-tTA;Ai93(GCaMP6f)) and VIP inhibitory (VIP-IRES-Cre;Ai162(GCaMP6f)) neurons in V1. Excitatory cells were sampled at 2 depths: 175um (L2/3) and 375um (L5). VIP cells were sampled at 175um depth.\n",
    "\n",
    "In this notebook, we will describe the core components of each experimental session and the tools for accessing and analyzing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>Let's get started\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you will need these libraries for computation & data manipulation\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# matplotlib is a standard python visualization package\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# seaborn is another library for statistical data visualization\n",
    "# seaborn style & context settings make plots pretty & legible\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', font_scale=1.5, rc={'lines.markeredgewidth': 2})\n",
    "sns.set_style('white')\n",
    "sns.set_palette('deep');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import allensdk modules for loading and interacting with the data\n",
    "from allensdk.brain_observatory.behavior.swdb import behavior_project_cache as bpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The first thing we will do is use the <code>allensdk</code> to load a cache for the visual behavior dataset, which contains a dataframe describing the dimensions of the dataset and methods for loading the data from particular sessions. You can inspect the <code>experiment_table</code> contained in the cache to identify experiments of interest and their metadata. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS path\n",
    "cache_path = r'/data/dynamic-brain-workshop/visual_behavior/2019'\n",
    "\n",
    "# # Mac/Linux path\n",
    "# cache_path = r'/Volumes/Brain2019/dynamic-brain-workshop/visual_behavior/2019'\n",
    "\n",
    "# # Windows path\n",
    "# cache_path = r'H:\\dynamic-brain-workshop\\visual_behavior\\2019'\n",
    "\n",
    "cache = bpc.BehaviorProjectCache(cache_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1.1:  Get information about what's in the dataset </b>\n",
    "\n",
    "<p>Read in <code>experiment_table</code> using the cache object and explore the columns to see the available visual areas, cre lines, and session types. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the table of all experiment sessions for this dataset\n",
    "experiments = cache.experiment_table\n",
    "experiments.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = cache.experiment_table\n",
    "experiments.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the dimensions of this dataset? \n",
    "print('targeted structures:', experiments.targeted_structure.unique())\n",
    "print('\\ncre_lines:', experiments.full_genotype.unique())\n",
    "print('\\nstage_types:', experiments.stage_name.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1.2: Get your experiment </b>\n",
    "\n",
    "<p>Get a random experiment ID for an active behavior session and assign it to a variable called <code>experiment_id</code>. Use pandas <code>sample()</code> to get a random experiment from a given column.\n",
    "  \n",
    " __[Documentation for pandas.sample() ](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sample.html)__ \n",
    "\n",
    "\n",
    "<p>What is the <code>targeted_structure</code>, <code>imaging_depth</code>, <code>full_genotype</code>, and <code>stage_name</code> for your <code>experiment_id</code>? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random active behavior experiment\n",
    "active_experiments = experiments[experiments.passive_session==False]\n",
    "experiment_id = active_experiments.ophys_experiment_id.sample(1).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the metadata for this experiment from the manifest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 1.3:  What is in an experiment container? </b>\n",
    "\n",
    "<p>The experiment container describes a set of imaging sessions performed at the same location (targeted structure and imaging depth) in the same mouse that targets the same set of cells. All the sessions in an experiment container have a common <code>experiment_container_id</code>.\n",
    "\n",
    "<p>Get a the <code>experiment_container_id</code> for your <code>experiment_id</code> and find out what other sessions were recorded at that same location. \n",
    "\n",
    "<p>Do all experiment containers have the same number of sessions associated with them? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the container ID for this experiment\n",
    "container_id = experiments[experiments.ophys_experiment_id==experiment_id]['container_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what other experiment sessions are in this container?\n",
    "experiments.groupby('container_id').get_group(container_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of sessions in each container\n",
    "experiments.groupby('container_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Behavior OPhys Session object</h2>\n",
    "<p>The BehaviorOphysSession class in allensdk.brain_observatory.behavior.behavior_ophys_session provides an interface to all of the data for a single experimental session from the Visual Behavior pipeline, aligned to a common time clock.\n",
    "\n",
    "<p>We package each session's data into a Neurodata Without Borders 2.0 (NWB) file. The BehaviorOphysSession will load data from the NWB file for a given session.\n",
    "    \n",
    "<p>You can load a BehaviorOphysSession object easily using the 'get_session' method of the cache object. \n",
    "\n",
    "<p>Use help() to view documentation on the session object. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a session from the cache\n",
    "session = cache.get_session(experiment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2.1:  What is an experiment session? </b>\n",
    "\n",
    "<p>Use tab completion to see what is in the dataset object for an experiment session\n",
    "\n",
    "<p>What is in the <code>metadata</code> attribute? What is in the <code>task_parameters</code> attribute?\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get session task parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Optical physiology data - max projection, roi masks, and fluorescence traces</h2>\n",
    "\n",
    "<p>Let's use the session object to access neuron fluorescence timeseries, roi masks, and metadata. An ROI mask is used to define the boundary of each cell in the flourescence data. The timeseries extracted from each ROI is one cell's activity.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2.2: Max intensity projection and ROI masks</b>\n",
    "    \n",
    "<p>Get the maximum intensity projection image using the <code>max_projection</code> attribute for your dataset and display it. \n",
    "    \n",
    "<p>Get the <code>segmentation_mask_image</code> and display it next to the max projection.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the max intensity projection and the segmentation mask\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "fig.set_size_inches(10, 5)\n",
    "ax[0].imshow(session.max_projection)\n",
    "ax[1].imshow(session.segmentation_mask_image)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">    \n",
    "<p>Get ROI mask for a single cell using the <code>roi_masks</code> attribute. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_specimen_ids = list(session.roi_masks.keys())\n",
    "plt.imshow(session.roi_masks[cell_specimen_ids[9]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2.3: Get dF/F traces and ophys timestamps</b>\n",
    "\n",
    "<p>Get <code>dff_traces</code> and <code>ophys_timestamps</code> attributes. How are they formatted?\n",
    "\n",
    "<p><code>dff_traces</code> is a dataframe with <code>cell_specimen_id</code> as the index and a column called <code>dff</code> which contains the baseline normalized fluorescence traces, also called dF/F traces, for each cell in the session. \n",
    "    \n",
    "<p><code>ophys_timestamps</code> is an array of timestamps corresponding to each 2P imaging frame. \n",
    "    \n",
    "<p>Check that the length of one of the dF/F traces is the same length as the ophys timestamps.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dff_traces \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the ophys_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get shape of traces and timestamps\n",
    "print('shape of dff_traces:',session.dff_traces.shape)\n",
    "print('shape of ophys_timestamps:',session.ophys_timestamps.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape of one cell's trace\n",
    "print('shape of one trace:',session.dff_traces.iloc[0]['dff'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 2.4: Plot the dF/F trace for a cell</b>\n",
    "\n",
    "<p>Plot the dF/F trace for one cell by indexing into the <code>dff_traces</code> array. You can get a specific row of the dataframe with .iloc, or use the cell_specimen_id to index with the .loc method. \n",
    "    \n",
    " __[Difference between .iloc and .loc](https://stackoverflow.com/questions/31593201/how-are-iloc-ix-and-loc-different)__ \n",
    "    \n",
    "<p>Use <code>ophys_timestamps</code> to plot the x-axis in seconds. \n",
    "    \n",
    "<p>Try plotting the trace for a few different cells.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dF/F trace for one cell using ophys timestamps for x-axis values\n",
    "# indexing method using row index with .iloc\n",
    "cell_index = 0 \n",
    "dff_trace = session.dff_traces.iloc[cell_index]['dff'] # note that the column name is outside of the .iloc call\n",
    "plt.plot(session.ophys_timestamps, dff_trace)\n",
    "plt.xlabel('time (sec)');\n",
    "plt.ylabel('dF/F');\n",
    "plt.title('cell index: '+str(cell_index));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the dF/F trace for one cell using ophys timestamps for x-axis values\n",
    "# indexing method using cell_specimen_id as index with .loc\n",
    "\n",
    "# get cell_specimen_id from a list of all cell_specimen_ids\n",
    "cell_specimen_ids = session.dff_traces.index.values\n",
    "cell_specimen_id = cell_specimen_ids[cell_index]\n",
    "\n",
    "dff_trace = session.dff_traces.loc[cell_specimen_id, 'dff'] #note how the column name is included in the .loc call\n",
    "plt.plot(session.ophys_timestamps, dff_trace)\n",
    "plt.xlabel('time (sec)');\n",
    "plt.ylabel('dF/F');\n",
    "plt.title('cell_specimen_id: '+str(cell_specimen_id));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Task 2.5: Plot a heatmap of all cell traces in this session</b>\n",
    "\n",
    "<p>Extract the <code>dff_traces</code> from the dataframe into an array using <code>np.vstack()</code>. What is the shape?\n",
    "\n",
    "<p>Use the matplotlib plotting function <code>pcolormesh</code> to plot the matrix as a heatmap. Plot the x-axis in seconds.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn dff_traces into an array of cells x timepoints\n",
    "dff_traces_array = np.vstack(session.dff_traces.dff.values)\n",
    "print('shape of dff_traces_array:',dff_traces_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a heatmap of all traces \n",
    "fig, ax = plt.subplots(figsize=(20,5))\n",
    "cax = ax.pcolormesh(dff_traces_array, cmap='magma', vmin=0, vmax=np.percentile(dff_traces_array, 99))\n",
    "ax.set_yticks(np.arange(0, len(dff_traces_array)), 10);\n",
    "ax.set_ylabel('cells')\n",
    "ax.set_xlabel('time (sec)')\n",
    "ax.set_xticks(np.arange(0, len(session.ophys_timestamps), 600*31));\n",
    "ax.set_xticklabels(np.arange(0, session.ophys_timestamps[-1], 600));\n",
    "cb = plt.colorbar(cax, pad=0.015, label='dF/F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Behavior timeseries and events - running, licks, and rewards </h2>\n",
    "<p>As the mouse performs the behavioral task, it is free to run on a disk. The task is a go/no-go style task with licking as the behavioral response. When a mouse correctly licks the water spout, a reward is delivered. \n",
    "\n",
    "<p>Running, licks and rewards are measured at the stimulus frame display rate and share timestamps with the stimulus. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3.1: Get running speed trace and timestamps</b>\n",
    "\n",
    "<p>Get the <code>running_speed</code> attribute of the dataset object. What does it contain? \n",
    "\n",
    "<p>Runnning speed shares timestamps with the visual stimulus. Compare the values of running timestamps from  <code>running_speed</code> with the values in the dataset attribute <code>stimulus_timestamps</code>. Note that all timestamps are in seconds. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get running speed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# what are the values of running speed timestamps?\n",
    "print('running speed timestamps:',session.running_speed.timestamps.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the values of stimulus timestamps?\n",
    "print('stimulus timestamps:',session.stimulus_timestamps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3.2: Plot running speed</b>\n",
    "\n",
    "<p>Plot the values for <code>running_speed</code> with time in seconds on the x-axis. \n",
    "    \n",
    "<p>Running speed is measured in cm/s. Label the axes appropriately.\n",
    "        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running speed with timestamps on x-axis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 3.3: Rewards and licks</b>\n",
    "    \n",
    "<p>Get the <code>rewards</code> attribute of the session object. How is it formatted? \n",
    "\n",
    "<p>Get the <code>licks</code> attribute of the session object. How is it formatted? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about rewards\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get information about licks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Task 3.4: Plot licking, reward times, and running speed</b>\n",
    "    \n",
    "<p>1) Plot <code>running_speed</code> as above, but set xlims to focus on a 30 second portion of the behavior session (ex: from x=600 to x=630). \n",
    "\n",
    "<p>2) On the same plot, plot <code>rewards</code> as points (not a line), at y = -10. Note that <code>rewards</code> is a dataframe, with timestamps as the index. Use the values of the index to get the times of all rewards to plot along the x-axis.\n",
    "\n",
    "<p>Hint: You will need to create an array of len(session.rewards.index.values) filled with -10 to use as y-axis values to plot. np.repeat() is a convenient function for this.\n",
    "\n",
    "<p>3) Add times of <code>licks</code> using plt.vlines() to your plot, with ymin=-10 and ymax=-5. \n",
    "\n",
    "<p>What is the relationship between running, licking and rewards? \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running speed, rewards, and licks\n",
    "plt.plot(session.running_speed.timestamps, session.running_speed.speed)\n",
    "plt.ylabel('running speed (cm/s)')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.xlim(600,630)\n",
    "plt.plot(session.rewards.index.values, np.repeat(-10, np.shape(session.rewards.index.values)), 'o')\n",
    "plt.vlines(session.licks,ymin=-10, ymax=-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Visual stimuli </h2>\n",
    "    \n",
    "<p>The timing of visual stimui can be accessed through the 'stimulus_presentations' table. This includes the timing of omitted stimuli - in other words, the time where the image would have been presented if it were not omitted.  \n",
    "    \n",
    "<p>The images shown during the session are included in the 'stimulus_template'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 4.1: Get the stimulus table</b>\n",
    "\n",
    "<p>Get the <code>stimulus_presentations</code> attribute to identify the times of stimulus presentations. How many stimulus flashes were there? \n",
    "\n",
    "<p>What other data is included for each stimulus flash in this table? What could it be used for?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the stimulus presentations table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many stimulus presentations were there? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the columns of the stimulus presentations table?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 4.2: Plot visual stimulus presentations with behavior events</b>\n",
    "\n",
    "<p>1) Copy and paste your code from Task 3.5\n",
    "\n",
    "<p>2) On the same plot, plot stimulus presentations using the <code>start_time</code> and <code>stop_time</code> columns with plt.axvspan(). Set alpha=0.3 & facecolor='gray'.\n",
    "\n",
    "<p>Hint: Loop through each row of the stimulus table using the pandas method <code>iterrows</code> to plot all stimulus flashes. \n",
    "    \n",
    " __[Documentation on pandas.iterrows()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iterrows.html)__ \n",
    "    \n",
    "<p>3) Bonus: Plot stimulus presentations corresponding to image changes using the <code>change</code> column. Set facecolor='blue' to distinguish from non-change flashes. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot running, rewards, licks and stimuli using axvspan to delineate periods where a stimulus was shown\n",
    "plt.plot(session.running_speed.timestamps, session.running_speed.speed)\n",
    "plt.ylabel('running speed (cm/s)')\n",
    "plt.xlabel('time (sec)')\n",
    "plt.xlim(600,630)\n",
    "plt.plot(session.rewards.index.values, np.repeat(-10, np.shape(session.rewards.index.values)), 'o')\n",
    "plt.vlines(session.licks,ymin=-10, ymax=-5)\n",
    "\n",
    "for index, row in session.stimulus_presentations.iterrows():\n",
    "    plt.axvspan(row.start_time, row.stop_time,alpha=0.3,facecolor='gray')\n",
    "    if row.change:\n",
    "        plt.axvspan(row.start_time, row.stop_time,alpha=0.3,facecolor='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 4.3: Get visual stimulus templates</b>\n",
    "\n",
    "<p>Get the <code>stimulus_templates</code> from the session object. How is it formatted? \n",
    "\n",
    "<p>The keys of the <code>stimulus_templates</code> dictionary correspond to the <code>image_names</code> in <code>stimulus_presentations</code>. The values are the images as arrays. \n",
    "    \n",
    "<p>Plot an image from <code>stimulus_templates</code>. Show the name of the image in the title.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the stimulus templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a stimulus using its image_name\n",
    "stimuli = session.stimulus_presentations.copy()\n",
    "image_name = stimuli[stimuli.image_name!='omitted'].image_name.unique()[0]\n",
    "plt.imshow(session.stimulus_templates[image_name], cmap='gray')\n",
    "plt.title(image_name);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>Behavior trials data</h2>\n",
    "    \n",
    "<p>The <code>trials</code> dataframe organizes behavior events (including licking and rewards), stimulus information (what stimulus was shown before and after the scheduled change time) and metadata (such as whether the trial was a 'go' trial or a 'catch' trial) for each behavioral trial. \n",
    "\n",
    "<p>This structure is convenient for data exploration and analysis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 5.1: Explore the trials table</b>\n",
    "\n",
    "<p>1) Get the <code>trials</code> attribute of the <code>session</code> object. What are the columns of this dataframe? What are the rows?\n",
    "\n",
    "<p>2) How many go trials were there? How many catch trials? What is the ratio of go to catch trials?\n",
    "\n",
    "<p>3) What images were shown in this behavior session? Use the pandas <code>unique()</code> method to get the unique images from the trials table. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the trials table \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many go trials were there? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many catch trials were there?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what images were shown? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 5.2: Get the hit and false alarm rates for this session</b>\n",
    "\n",
    "<p>The hit rate is the fraction of go trials with a lick in the reward window\n",
    "    \n",
    "<p>The false alarm rate is the fraction of catch trials with a lick in the reward window\n",
    "\n",
    "<p>1) Select all the go trials by filtering the dataframe by <code>go</code> = True. Get the fraction of go trials where <code>hit</code> = True. \n",
    "\n",
    "<p>2) Repeat for catch trials.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the hit rate for go trials\n",
    "go_trials = session.trials[session.trials.go]\n",
    "print(len(go_trials), 'go trials')\n",
    "print(np.sum(go_trials.hit), 'hits')\n",
    "print('hit rate:', round(np.sum(go_trials.hit)/len(go_trials),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the false alarm rate for catch trials\n",
    "catch_trials = session.trials[session.trials.catch]\n",
    "print(len(catch_trials),'catch trials')\n",
    "print(np.sum(catch_trials.false_alarm),'false alarms')\n",
    "print('false alarm rate:',round(np.sum(catch_trials.false_alarm)/len(catch_trials),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 5.3: Plot a lick raster across trials aligned to the change time</b>\n",
    "\n",
    "<p>Provide the <code>trials</code> dataframe to the function below to plot a lick raster.\n",
    "\n",
    "<p>Is the mouse performing the task consistently across the whole session?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lick_raster(trials):\n",
    "    trials = trials[trials.aborted==False]\n",
    "    trials = trials.reset_index()\n",
    "    fig,ax = plt.subplots(figsize=(5,10))\n",
    "    for trial_index, trial_data in trials.iterrows(): \n",
    "        # get times relative to change time\n",
    "        lick_times = [(t - trial_data.change_time) for t in trial_data.lick_times]\n",
    "        reward_time = [(t - trial_data.change_time) for t in [trial_data.reward_time]]\n",
    "        # plot reward times\n",
    "        if len(reward_time) > 0:\n",
    "            ax.plot(reward_time[0], trial_index + 0.5, '.', color='b', label='reward', markersize=6)\n",
    "        # plot lick times\n",
    "        ax.vlines(lick_times, trial_index, trial_index + 1, color='k', linewidth=1)\n",
    "        # put a line at the change time\n",
    "        ax.vlines(0, trial_index, trial_index + 1, color=[.5, .5, .5], linewidth=1)\n",
    "    # gray bar for response window\n",
    "    ax.axvspan(0.1, 0.7, facecolor='gray', alpha=.3, edgecolor='none')\n",
    "    ax.grid(False)\n",
    "    ax.set_ylim(0, len(trials))\n",
    "    ax.set_xlim([-1, 4])\n",
    "    ax.set_ylabel('trials')\n",
    "    ax.set_xlabel('time relative to change (sec)')\n",
    "    ax.set_title('lick raster')\n",
    "    plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the lick raster for this session using the provided function\n",
    "make_lick_raster(session.trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h2>The Trial Response and Flash Response dataframes organize cell responses by behavior trials and stimulus flashes </h2>\n",
    "    \n",
    "<p> We have done the work of temporal alignment for you to create these two dataframes that provide a convenient data structure for analysis. \n",
    "  \n",
    "<p> The <code>trial_response_df</code> extracts cell responses for each behavioral trial in a [-4,8] second window around the change time.\n",
    "    \n",
    "<p> The <code>flash_response_df</code> extracts cell responses for each stimulus presentation in a [-0.5, 0.75] second window around each flash. \n",
    "    \n",
    "<p> Both dataframes take the mean response for each cell in a 500ms window after the change time for trials, or after the stimulus onset time for stimulus presentations.\n",
    "    \n",
    "<p> These dataframes also include a column called <code>p_value</code>, comparing the response for each cell on each trial to a shuffled distribution from the spontaneous activity epochs. There is also a column called <code>pref_stim</code> with a Boolean indicating the image that drove the strongest mean response for each cell.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 6.1: Load and explore the Trial Response Dataframe</b> \n",
    "\n",
    "<p>1) Get the <code>trial_response_df</code> attribute of the session object. What are the columns? What are the rows? What is different than the <code>trials</code> table? \n",
    "    \n",
    "<p>The <code>dff_trace</code> column contains a portion of each cell's dF/F trace from 4 seconds before the <code>change_time</code> to 8 seconds after the <code>change_time</code> for each trial. There are also <code>dff_trace_timestamps</code> for the same window. \n",
    "\n",
    "<p> For each trial, the <code>mean_response</code> of each cell is computed for a 500ms window after the <code>change_time</code>.\n",
    "\n",
    "<p>2) Assign <code>trial_response_df</code> to a variable named <code>tr</code> for convenient use in later exercises.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get the trial response dataframe and assign it to 'tr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is in the trial response dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 6.2: Plot the population average trace for go trials </b>\n",
    "\n",
    "<p>Select go trials from the <code>trial_response_df</code>, take the mean across all cells, all trials, and plot it. \n",
    "    \n",
    "<p>Bonus: plot the x-axis in seconds relative to the change time\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across all cells for go trials\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "traces = tr[tr.go==True].dff_trace.values\n",
    "mean_trace = np.mean(traces, axis=0)\n",
    "time_seconds = tr.iloc[0].dff_trace_timestamps  - tr.iloc[0].change_time\n",
    "ax.plot(time_seconds, mean_trace)\n",
    "ax.set_xlabel('time (sec)');\n",
    "ax.set_ylabel('mean dF/F');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<p><b>Task 6.3: Plot the population response across cells for one change trial</b>\n",
    "\n",
    "<p>1) Select one <code>trial_id</code> where <code>go</code> = True and filter the <code>trial_response_df</code> to get the data for just that trial. How many rows are in this subset of data? Is it the same length as the number of unique cells?\n",
    "\n",
    "<p>2) Get the <code>mean_response</code> for all cells,  sort in order of response magnitude and plot it. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data for all cells for a single go trial\n",
    "go_trials = tr[tr.go==True].trial_id.values\n",
    "some_go_trial = go_trials[10]\n",
    "\n",
    "trial_data = tr[tr.trial_id==some_go_trial]\n",
    "trial_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean response across cells for this trial, with cells on x-axis and mean dF/F on y-axis\n",
    "plt.plot(np.sort(trial_data.mean_response.values), 'o')\n",
    "plt.ylabel('mean dF/F');\n",
    "plt.xlabel('sorted cells');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Task 6.4: Explore the flash response dataframe</b>\n",
    "\n",
    "<p>What is in the <code>flash_response_df</code> attribute of the session object? What are the columns? What are the rows?  How is it different from the <code>stimulus_presentations</code> table?\n",
    "\n",
    "<p>The <code>flash_response_df</code> contains the cell responses for individual stimulus presentations, aka flashes. It contains the <code>mean_response</code> of every cell in a 500ms window after every stimulus onset, for all stimulus presentations during the behavior session.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the flash response dataframe and assign it to 'fr'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whats in the flash response dataframe?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Task 6.5: Plot the mean trace for each image across all flashes</b>\n",
    "\n",
    "<p>1) Select one image and plot the mean response across all cells using the <code>dff_trace</code> column. Put the <code>image_name</code> in the title. \n",
    "    \n",
    "<p>2) Plot the mean response to all images on the same figure. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across all cells for one image\n",
    "image_names = fr.image_name.unique()\n",
    "image_name = image_names[0]\n",
    "traces = fr[fr.image_name==image_name].dff_trace\n",
    "mean_image_trace = np.mean(traces, axis=0)\n",
    "time_seconds = fr.iloc[0].dff_trace_timestamps  - fr.iloc[0].start_time\n",
    "plt.plot(time_seconds, mean_image_trace);\n",
    "plt.title(image_name);\n",
    "plt.ylabel('dF/F')\n",
    "plt.xlabel('time relative to stimulus onset (sec)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across cells separately for each image\n",
    "image_names = np.sort(fr.image_name.unique())\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for image_name in image_names: \n",
    "    traces = fr[fr.image_name==image_name].dff_trace\n",
    "    mean_image_trace = np.mean(traces, axis=0)\n",
    "    time_seconds = fr.iloc[0].dff_trace_timestamps  - fr.iloc[0].start_time\n",
    "    ax.plot(time_seconds, mean_image_trace, label=image_name);\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.set_ylabel('dF/F')\n",
    "ax.set_xlabel('time relative to stimulus onset (sec)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "    <p><b>Task 6.6: Plot one cell's response to each image across all flashes</b>\n",
    "    \n",
    "<p>Create the same plot for a single cell rather than the whole population. \n",
    "    \n",
    "<p>What does it look like for different cells?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean trace across images for one cell\n",
    "cell_specimen_ids = fr.cell_specimen_id.unique()\n",
    "cell_specimen_id = cell_specimen_ids[4]\n",
    "cell_data = fr[fr.cell_specimen_id==cell_specimen_id]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "image_names = np.sort(fr.image_name.unique())\n",
    "for image_name in image_names: # loop through images\n",
    "    traces = cell_data[cell_data.image_name==image_name].dff_trace # get traces for one image\n",
    "    mean_image_trace = np.mean(traces, axis=0)\n",
    "    time_seconds = fr.iloc[0].dff_trace_timestamps  - fr.iloc[0].start_time\n",
    "    ax.plot(time_seconds, mean_image_trace, label=image_name);\n",
    "ax.legend(bbox_to_anchor=(1,1))\n",
    "ax.set_ylabel('dF/F');\n",
    "ax.set_xlabel('time relative to stimulus onset (sec)');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "visual_behavior_sdk",
   "language": "python",
   "name": "visual_behavior_sdk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
