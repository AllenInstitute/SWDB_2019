{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/cropped-SummerWorkshop_Header.png\">  \n",
    "\n",
    "<h1 align=\"center\">Neuropixels Extracellular Electrophysiology </h1> \n",
    "<h2 align=\"center\">Summer Workshop on the Dynamic Brain </h2> \n",
    "<h3 align=\"center\">Wednesday, August 22, 2018</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../resources/EphysObservatory/neuropixels.png\" height=\"250\" width=\"250\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<p>This notebook will introduce you to Neuropixels spiking datasets. We will describe the structure of the data and then walk through basic analysis methods for accesssing, analyzing, and visualizing spike train data.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<b>Datasets:</b>\n",
    "<ul>\n",
    "<li>extracellular action potential recordings</li>\n",
    "<li>populations of single neurons in mouse brain</li>\n",
    "<li>passive visual stimulation in awake mouse</li>\n",
    "<li>battery of stimuli including drifting gratings and natural scenes</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<b>Note:</b>\n",
    "\n",
    "These pre-release datasets were collected during piloting for our new Ephys Brain Observatory. Pipeline data collection has just begun (August 2018) and production data will be released online in 2019.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<b>Today's Agenda:</b>\n",
    "<ol>\n",
    "<li>Overview of Neuropixels spiking datasets  </li>\n",
    "<li>Analysis and visualization of stimulus-evoked activity</li>\n",
    "<li>Correlations and cross-correlogram</li>\n",
    "<li>Waveform and spike pattern analysis for cell classification</li>\n",
    "<li>Project ideas</li>\n",
    "</ol>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h2>Drive path and imports</h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<b>Make sure your drive path is correct!</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make sure your drive path is correct! \n",
    "# macOS/OS X\n",
    "# drive_path = '/Volumes/Brain2018/visual_coding_neuropixels'\n",
    "\n",
    "# Windows (a good guess)\n",
    "# drive_path = 'e:/visual_coding_neuropixels'\n",
    "\n",
    "# Linux (will vary; the following is possibly what Ubuntu will do)\n",
    "# drive_path = '/media/Brain2018/visual_coding_neuropixels'\n",
    "\n",
    "# AWS\n",
    "drive_path = '/data/dynamic-brain-workshop/visual_coding_neuropixels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We need to import these modules to get started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h1>1. Overview of datasets</h1>\n",
    "\n",
    "<b>Brain areas:</b>\n",
    "<ul>\n",
    "    <li>Single-probe experiments: VISp</li>\n",
    "    <li>Multi-probe experiments: VISp + higher visual areas (VISam, VISpm, VISrl, VISl, VISal)</li>\n",
    "</ul>\n",
    "    \n",
    "<b>Visual stimuli:</b>\n",
    "<ul>\n",
    "    <li>Passive visual stimulation using Brain Observatory - Visual Coding 1.1 stimulus sets</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Provide path to manifest file\n",
    "manifest_file = os.path.join(drive_path,'ephys_manifest.csv')\n",
    "\n",
    "# Create a dataframe \n",
    "expt_info_df = pd.read_csv(manifest_file)\n",
    "\n",
    "# Display information contained in the dataframe\n",
    "expt_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make new dataframe by selecting only single-probe experiments\n",
    "single_probe_expt_info = expt_info_df[expt_info_df.experiment_type == 'single_probe']\n",
    "\n",
    "print('Number of single-probe experiments: %s') %len(single_probe_expt_info)\n",
    "\n",
    "# Display information about single probe expts\n",
    "single_probe_expt_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.1:</b> Make a dataframe for 'multi_probe' experiments. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "\n",
    "#make new dataframe by selecting only multi-probe experiments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.2:</b> How many multi-probe experiments?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Load dataset for one multi-probe experiment using NWB file adapter</h3>\n",
    "\n",
    "<ul>\n",
    "<li>Datasets are stored as NWB1.0 files which is based on HDF5 file format</li>\n",
    "<li>To facilitate access to these files we have built a light-weight adapter object (NWB_adapter)</li>\n",
    "<li>The NWB_adapter provides easy access to unit spike times and stimulus presentation metadata</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import NWB_adapter\n",
    "from swdb_2018_neuropixels.ephys_nwb_adapter import NWB_adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose filename from one row from the multi_probe experiments dataframe\n",
    "multi_probe_example = 1 # index to row in multi_probe_expt_info\n",
    "multi_probe_filename  = multi_probe_expt_info.iloc[multi_probe_example]['nwb_filename']\n",
    "print multi_probe_filename\n",
    "\n",
    "# Specify full path to the .nwb file\n",
    "nwb_file = os.path.join(drive_path,multi_probe_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>We will be using the data contained in this experiment for the remainder of this notebook.\n",
    "\n",
    "<h2>The Dataset Object</h2>\n",
    "<p>We will create a data_set object for this experiment session.\n",
    "\n",
    "<p>The data_set object contains methods and info about the data recorded in this experiment\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_set = NWB_adapter(nwb_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.3:</b> What are the attributes of the data_set object? Use either `dir` or tab-completion to find out what methods and info the `data_set` object has.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "#data_set.  #\"tab completion\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3> probe_list and region_list</h3>\n",
    "\n",
    "<p>Let's look at the cortical regions from which data was recorded in this experiment. For all datasets provided, each of the probes records from a unique cortical region in the order shown below.\n",
    "\n",
    "<p> This information is contained in 'probe_list' and 'region_list' in the data_set object\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Probe names and corresponding cortical regions\n",
    "data_set.probe_list, data_set.region_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.4:</b> Which probe has the most recorded units in this experiment? Hint: Look at number_cells attribute.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p> So 'number_cells' is  a dictionary that stores number of units recorded on each probe with probe names as keys.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>unit_list</h3>\n",
    "\n",
    "<p> 'unit_list' in data_set is  a dictionary that stores unit IDs from each probe. Unit IDs in recorded on each probe can be accessed by providing a probe name as key.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of all units recorded on probeC\n",
    "probeC_unit_list = data_set.unit_list['probeC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.5:</b> Print the unit ID for the first 20 units in probeC_unit_list\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "# print unit ID for first 20 units\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b> Task 1.6:</b> How many units were recorded on probeC in this experiment?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>unit_df</h3>\n",
    "The metadata for each recorded unit is outlined in 'unit_df' as a dataframe. For each recorded unit, this dataframe contains:\n",
    "<ol>\n",
    "<li>the unit_id</li>\n",
    "<li>the probe on which this unit was recorded</li>\n",
    "<li>the brain structure</li>\n",
    "<li>the signal-to-noise ratio of the spike waveform</li>\n",
    "<li>the depth from the cortical surface</li>\n",
    "<li>the probe channel on which it was recorded (useful for later) </li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Look at the first five entries in the unit_df dataframe\n",
    "data_set.unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# List of structures from which units were recorded\n",
    "np.unique(data_set.unit_df['structure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Spike times</h3>\n",
    "\n",
    "<p>'spike_times' is a dictionary with probe name as keys. \n",
    "    \n",
    "<p>We will look at spiketimes of units in VISp. Recall from above that these are on probeC. \n",
    "<p>To do this, we have to first isolate units on probeC that were in VISp. We will use 'unit_df' and create a dataframe that is a subset of unit_df \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify the probe\n",
    "probe_name = 'probeC'\n",
    "\n",
    "# Speciy the region\n",
    "region_name = 'VISp'\n",
    "\n",
    "# Subset df\n",
    "v1_unit_df = data_set.unit_df[data_set.unit_df['structure']==region_name]\n",
    "\n",
    "# Display first 5 entries\n",
    "v1_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make a list of unit_ids that are in VISp on probeC\n",
    "v1_unit_list = list(v1_unit_df['unit_id'].values)\n",
    "\n",
    "# How many units in VISp? \n",
    "print len(v1_unit_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h4>Extract spike_times corresponding to units on probeC.</h4>\n",
    "    \n",
    "<p>This returns a dictionary with unit IDs as keys. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all spike times from probeC units\n",
    "probe_spikes = data_set.spike_times[probe_name]\n",
    "\n",
    "# Look at the first 5 unit IDs in probe_spikes\n",
    "print probe_spikes.keys()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<b>Get spike times from single unit in VISp</b>\n",
    "\n",
    "<p> We will do this by specifying a unit of interest in 'v1_unit_list' and providing that as a key to 'probe_spikes'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unit_of_interest = v1_unit_list[3]        # Specify unit of interest\n",
    "\n",
    "spikes = probe_spikes[unit_of_interest]   # Obtain spike times of this unit\n",
    "\n",
    "spikes[:20]                               # List the first 20 spiketimes of this unit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 1.7:</b> How many spikes were recorded from our 'unit_of_interest'?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 1.1:</b> Plot a histogram showing spike count across the population of units recorded in VISp. \n",
    "\n",
    "<ol>\n",
    "    <li>Create an empty list called 'num_spikes'.</li>\n",
    "    <li>Loop through all units in 'v1_unit_list' and append the number of spikes for each unit to 'num_spikes'. Make sure to use 'probe_spikes' and pass unit_id as a key when you loop through.</li>\n",
    "    <li>Use plt.hist to plot the histogram. You can specify 'bins=20' in plt.hist</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Raster plot of spike times over some time interval in session</h3>\n",
    "\n",
    "<p>We have isolated spike times from a unit in VISp and stored it in 'spikes'. We can visualize them using a raster plot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make raster plot of single unit spike trains within a specified time window\n",
    "\n",
    "tst = 0  #start time in sec\n",
    "tend = 300 #end time in sec\n",
    "\n",
    "#Plot figure\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,1))\n",
    "ax.plot(spikes,np.ones_like(spikes),'|')\n",
    "ax.set_xlim(tst,tend)\n",
    "\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_title('Spike train for 1 unit in VISp over first 5 minutes of experimental session')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 1.2</b>  Plot raster of spike train in 'spikes' from 10 mins to 15 mins.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h4>Plot spike times from all VISp neurons for the first five minutes</h4>\n",
    "\n",
    "<p> We will do this by creating a figure object and plotting rasters by looping through all units in VISp\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tst = 0\n",
    "tend = 300\n",
    "\n",
    "# Figure setup\n",
    "fig,ax = plt.subplots(1,1)\n",
    "fig.set_size_inches(15,8)\n",
    "\n",
    "# Loop through list of spike times from each unit and plot at different y-values\n",
    "for i,unit in enumerate(v1_unit_list):\n",
    "    spike_times = probe_spikes[unit]\n",
    "    ax.plot(spike_times,i*np.ones_like(spike_times),'|')\n",
    "\n",
    "#Annotate plot\n",
    "plt.xlim(tst,tend)\n",
    "\n",
    "ax.set_ylabel('units')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_title('Spike train for all V1 units over first 5 minutes of experimental session')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 1.3:</b> Make a series of rasters plots showing spiking activity from 20 units recorded from each of the 6 visual cortical areas. To do this,\n",
    "\n",
    "<ol>\n",
    "    <li>Loop over probes--extract all spikes from probe within this loop.</li>\n",
    "    <li>Use function below (**get_units_in_visual_cortex()** ) to return only visual cortical neurons.</li>\n",
    "    <li>Loop over 20 units in each area--extract unit spike times from probe_spikes and plot raster.</li>\n",
    "</ol>\n",
    "\n",
    "<b>HINT:</b> Recall from above that each probe corresponds to a unique visual cortical region. To loop over probes and get the corresponding region for 'get_units_in_visual_cortex', use the <b>zip</b> function in python.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_units_in_visual_cortex(cortical_region_name, data_set):\n",
    "    '''Inputs:\n",
    "            cortical_region_name: the name of visual cortical region ('VISp','VISl','VISal','VISrl','VISam','VISpm')\n",
    "            data_set: data_set object for one ephys experiment\n",
    "       Returns:\n",
    "            vis_unit_list: list of unit_IDs in the cortical region '''\n",
    "    \n",
    "    # Select dataframe subset of units in cortical region\n",
    "    subset_unit_df = data_set.unit_df[data_set.unit_df['structure']==cortical_region_name]\n",
    "    \n",
    "    # Make a list of unit_ids that are in visual cortical region on specified probe\n",
    "    vis_unit_list = list(subset_unit_df['unit_id'].values)\n",
    "    \n",
    "    return vis_unit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "# Raster plot showing 20 units simultaneously recorded in each of 6 areas\n",
    "\n",
    "#Get probes and regions in data_set\n",
    "probes = \n",
    "regions = \n",
    "\n",
    "# Figure setup\n",
    "fig,ax = plt.subplots(3,2,figsize=(15,7),sharex=True,sharey=True)\n",
    "\n",
    "#The ravel command gets the six axes (3*2) into a single list.\n",
    "ax = ax.ravel()     \n",
    "\n",
    "#List of colors so that a unique color can be used for each plot. \n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# Loop over probes. Use a counter variable 'idx' that increments by 1 for every probe\n",
    "\n",
    "\n",
    "    \n",
    "    # Plot spike times for 20 units\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h1>2. Visualization and analysis of stimulus-evoked activity</h1>\n",
    "\n",
    "<p> We will now look at analyses of stimulus-evoked activity for a few stimuli.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h4>Example units</h4>\n",
    "\n",
    "<p> For the multi-probe experiments, the data_set object contains a dictionary of example units. We will use these to illustrate stimulus-evoked activity. <p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 2.1:</b> What are the keys of the example_units dictionary?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "We will store the information from 'example_units' in several variables for ease of use below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ex_probe = data_set.example_units['probe']        #example probe\n",
    "ex_unit_ids = data_set.example_units['unit_ids']   #example unit_ids\n",
    "ex_structure = data_set.example_units['structure']  #example_structure\n",
    "\n",
    "print(ex_probe, ex_unit_ids, ex_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Stimulus table</h3>\n",
    "<ul>\n",
    "    <li>Stimulus presentation information is found in the stimulus table</li>\n",
    "    <li>The stim table for each stimulus type is accessed via stim_tables dictionary</li>\n",
    "    <li>The keys of stim_tables are names of the stimulus sets</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#What are the keys of stim_tables?\n",
    "data_set.stim_tables.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 2.2:</b> Get the stimulus table for natural scenes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "\n",
    "# Get the stim table for natural scenes\n",
    "ns_table = data_set.get_stimulus_table('natural_scenes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ns_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "The above table shows the start and end time of presentation of each natural scene stimulus. Each scene has a unique image ID given by the 'frame' column \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 2.3:</b> How many presentations of image 46 are there in this experiment?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Trial-wise raster plot</h3>\n",
    "<ul>\n",
    "    <li>We'll now use the stim table to identify when image #46 was presented</li>\n",
    "    <li>From this we'll extract spikes around each presentation of image #46</li>\n",
    "    <li>Finally we'll make a raster plot showing spikes on each trial</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select trials from stim table for specific image_id\n",
    "image_id = 46\n",
    "ns_table_subset = ns_table[ns_table.frame==image_id] # This is the stim table for image 46\n",
    "ns_table_subset.head(3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Select spikes times from example probe\n",
    "ex_probe_spikes = data_set.spike_times[ex_probe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get spikes for all repeats of image 46 for ONE example unit on our example probe\n",
    "\n",
    "# Time before and after image presention\n",
    "pre_time = 1.\n",
    "post_time = 1.\n",
    "\n",
    "# Get spike times from first unit in example list\n",
    "unit_spikes = ex_probe_spikes[ex_unit_ids[0]]\n",
    "\n",
    "# Make list that will contain spike train for each image presentation\n",
    "all_trials_spikes = []\n",
    "\n",
    "#Loop through every presentation of image 46\n",
    "for i,start in enumerate(ns_table_subset.start):\n",
    "    \n",
    "    # Extract spikes around stimulus Start time\n",
    "    spikes_each_trial = unit_spikes[(unit_spikes > start-pre_time) & (unit_spikes <= start+post_time)]\n",
    "    \n",
    "    #Subtract start time of stimulus presentation\n",
    "    spikes_each_trial = spikes_each_trial - start\n",
    "    \n",
    "    #Add list of spikes to main list\n",
    "    all_trials_spikes.append(list(spikes_each_trial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Plot raster for given unit in VISal for image 46\n",
    "\n",
    "# Figure setup\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "\n",
    "# Make raster plot\n",
    "for i,tr_spikes in enumerate(all_trials_spikes):\n",
    "    ax.plot(tr_spikes,i*np.ones_like(tr_spikes),'|',color='b')\n",
    "    ax.invert_yaxis()\n",
    "\n",
    "# Stimulus presentation window\n",
    "stimulus_duration = ns_table_subset.end.values[0] - ns_table_subset.start.values[0]\n",
    "ax.axvspan(0,stimulus_duration,color='gray',alpha=0.2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 2.1:</b> Write a function to plot raster for a given unit and image. Use your function to plot rasters for the 6 example units for image 46. Your function should have the following signature:\n",
    "\n",
    "<pre><code>\n",
    "def image_raster(img, unit_spikes, ax):\n",
    "    #your code here\n",
    "    return ax\n",
    "</code></pre>\n",
    "\n",
    "where: \n",
    "<ul>\n",
    "    <li>img: the stim table for 1 image</li>\n",
    "    <li>unit_spikes: the spike times for 1 unit</li>\n",
    "    <li>ax: the handle of a matplotlib axes object (the modified handle is also the return value)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def \n",
    "    \n",
    "    #Default params\n",
    "    if not ax:\n",
    "        fig,ax = plt.subplots(1,1,figsize=(6,3))\n",
    "\n",
    "    pre_time = .5\n",
    "    post_time = .75\n",
    "\n",
    "    all_trials = []\n",
    "    # Get spike train for each trial and append to all_trials\n",
    "    \n",
    "\n",
    "    # Plot raster for each trial\n",
    "      \n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reminder: we stored info of example units in these variables:\n",
    "print(ex_probe, ex_unit_ids, ex_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get spikes on example probe\n",
    "ex_probe_spikes = data_set.spike_times[ex_probe]\n",
    "\n",
    "# Get stim table for natural scene = 46\n",
    "image_id = 46\n",
    "img = ns_table[ns_table.frame==image_id]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 2.1 (contd.):</b> Plot rasters for the above 6 example units for image 46 using your function. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "fig,ax = plt.subplots(2,3,figsize=(16,7),sharex=True,sharey=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "#Loop through example units\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Peri-stimulus time histogram (PSTH)</h3>\n",
    "\n",
    "The PSTH is used to visualize the firing rate of a neuron over time relative to a stimulus presentation event. The firing rate is computed by counting the number of spikes in a given time-window and dividing by the window-size.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get spikes for all repeats of image 46 for a single unit in VISal \n",
    "\n",
    "# Get spikes for example unit\n",
    "unit = ex_unit_ids[0]\n",
    "unit_spikes = ex_probe_spikes[unit]\n",
    "\n",
    "# Make a list with spike train for each stimulus presentation trial\n",
    "all_trials_spikes = []\n",
    "\n",
    "#Loop through all repeats. \n",
    "for i,start in enumerate(ns_table_subset.start):\n",
    "    trial_spikes = unit_spikes[(unit_spikes > start-pre_time) & (unit_spikes < start+post_time)]\n",
    "    trial_spikes = trial_spikes - start\n",
    "    all_trials_spikes.append(list(trial_spikes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make PSTH for each trial with 10 ms bins\n",
    "\n",
    "# Time before and after image presention\n",
    "pre_time = 1.\n",
    "post_time = 1.\n",
    "\n",
    "bin_width = 0.01                 #time-window-size to bin spikes\n",
    "bins = np.arange(-pre_time,post_time+bin_width,bin_width)   # time bins\n",
    "\n",
    "fr_per_trial = []                 #empty list to store firing rates per trial\n",
    "\n",
    "#Loop through all trials\n",
    "for trial_spikes in all_trials_spikes:\n",
    "    counts,edges = np.histogram(trial_spikes,bins)      #\n",
    "    counts = counts/bin_width#np.diff(bins[0:2])\n",
    "    fr_per_trial.append(counts)\n",
    "\n",
    "centers = edges[:-1] + np.diff(bins)/2  #bin centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Calculate mean firing rate across all trials\n",
    "mean_fr = np.mean(fr_per_trial,axis=0)\n",
    "\n",
    "# Plot mean PSTH across trials\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.plot(centers,mean_fr)\n",
    "ax.axvspan(0,0.25,color='gray',alpha=0.1)\n",
    "ax.set_ylabel('Firing rate (spikes/second)')\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_title('unit_id: ' + unit)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 2.2:</b> Write a function to plot PSTH for a given unit and image. Use your function to plot PSTHs for 6 example units for image 46. Use a bin_width of 5 ms to bin spikes. Your function should have the following signature:\n",
    "\n",
    "<pre><code>\n",
    "def image_psth(img, unit_spikes, ax):\n",
    "    #your code here\n",
    "    return ax\n",
    "</code></pre>\n",
    "\n",
    "where: \n",
    "<ul>\n",
    "    <li>img: the stim table for 1 image</li>\n",
    "    <li>unit_spikes: the spike times for 1 unit</li>\n",
    "    <li>ax: the handle of a matplotlib axes object (the modified handle is also the return value)</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "def image_psth(img,unit_spikes,ax=[]):\n",
    "    \n",
    "    #Default params\n",
    "    if not ax:\n",
    "        fig,ax = plt.subplots(1,1,figsize=(6,3))\n",
    "\n",
    "    pre_time = 1.\n",
    "    post_time = 1.\n",
    "\n",
    "    all_trials = []\n",
    "    # Get spike train for each trial\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Make PSTH for each trial with 5 ms bins\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Plot mean PSTH across trials\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Figure setup\n",
    "fig,ax = plt.subplots(2,3,figsize=(16,7),sharex=True,sharey=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Trial averaged response and tuning curves</h3>\n",
    "\n",
    "<p> We plotted rasters and mean firing rates in response to a natural scene. \n",
    "<p>We will next see how to use the averaged responses across different sweeps/trials of drifting gratings to calculate **orientation tuning curves** of single neurons \n",
    "<p> The orientation tuning curve is calculated from the average responses for different orientations of drifting gratings a fixed spatial and temporal frequency.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get drifting gratings stim table\n",
    "dg_stim_full = data_set.get_stimulus_table('drifting_gratings')\n",
    "dg_stim_full.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 2.4</b>  Make a variable stim_table_ori_90 from dg_stim_full after selecting for orientation = 90. What are the unique temporal frequencies?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "We'll now make an orientation tuning curve for an example unit using only TF = 4.0 Hz\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First Make stimulus table for drifting gratings with TF = 4.0\n",
    "dg_stim = dg_stim_full[(dg_stim_full.temporal_frequency==4.0)]\n",
    "\n",
    "# Get list of unique stimulus orientations\n",
    "oris = sorted(dg_stim.orientation.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "We will calculate the mean and sem (standard error of mean) of the firing rates for every trial with a given orientation. We will store the results in a dictionary called <b>trial_averaged_response</b>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean response over all orientations\n",
    "\n",
    "# Example unit\n",
    "unit_spikes = ex_probe_spikes[ex_unit_ids[0]]\n",
    "\n",
    "## Dictionary to store trial responses\n",
    "#trial_response = {}\n",
    "\n",
    "# Window to compute firing rate\n",
    "window_size = 0.25\n",
    "\n",
    "# Dictionary to hold results\n",
    "trial_averaged_response = {'Ori':[],'fr_mean':[],'fr_sem':[]}\n",
    "\n",
    "# Loop over orientations\n",
    "for ori in oris:\n",
    "    \n",
    "    tmp = dg_stim[dg_stim.orientation==ori]   #subset stim table for fixed ori\n",
    "    fr = []                                  #empty list to store firing rates\n",
    "    \n",
    "    # Loop over trials/sweeps\n",
    "    for i,start in enumerate(tmp.start):\n",
    "        spikes = unit_spikes[(unit_spikes > start) & (unit_spikes <= start+window_size)]   #collect spikes in window\n",
    "        fr.append(len(spikes)/window_size)    #count total number of spikes in window and divide by window size\n",
    "    \n",
    "    trial_averaged_response['Ori'].append(ori)\n",
    "    trial_averaged_response['fr_mean'].append(np.mean(fr))           #Mean firing rate over time = window_size\n",
    "    trial_averaged_response['fr_sem'].append(np.std(fr)/np.sqrt(len(fr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<b>plt.errorbar(x,y,yerr)</b> allows you to plot y vs x along with the standard deviation (sem) at every point.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot tuning curve\n",
    "plt.errorbar(x=trial_averaged_response['Ori'],y=trial_averaged_response['fr_mean'],yerr=trial_averaged_response['fr_sem'])\n",
    "plt.xticks(oris)\n",
    "plt.ylabel('Firing rate (spikes/second)')\n",
    "plt.xlabel('Orientation (degrees)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>The tuning curve above shows that our chosen unit is selective for **horizontal** drifting gratings. \n",
    "<p>We can perform a similar analysis for static gratings and check if the results hold. \n",
    "<p>In the interest of time, we leave that for **homework**. Please come talk to us regarding solutions\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Homework 2.1</b> Compute tuning curve for static gratings. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Homework 2.2</b>  Plot rasters for each orientation of static and drifting gratings to compare temporal dynamics.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h1>3. Correlations and cross-correlogram</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Correlation between two neurons</h3>\n",
    "\n",
    "<p> Next, we consider correlated activity between neurons at different timescales by computing signal and noise correlations and pairwise cross-correlograms\n",
    "<p> We start with signal correlations for drifting gratings\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get stimulus table \n",
    "dg = data_set.get_stimulus_table('drifting_gratings')\n",
    "\n",
    "# Select TF = 4.0\n",
    "dg_stim = dg[(dg.temporal_frequency==4.0)]\n",
    "\n",
    "# Get orientation conditions\n",
    "oris = sorted(dg_stim.orientation.unique())\n",
    "\n",
    "# Get number of trials\n",
    "n_trials_dg = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize dataframe\n",
    "dg_stim.loc[dg_stim.orientation.values==oris[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example units\n",
    "ex_probe_spikes = data_set.spike_times[ex_probe]\n",
    "units = ex_unit_ids[:2]#[ex_unit_ids[0],ex_unit_ids[4]]#\n",
    "\n",
    "# Time window to compute firing rate\n",
    "window = 0.25\n",
    "\n",
    "# Define mean response matrix with dimension: neuron*ori*trial\n",
    "dg_response = np.zeros([len(units), len(oris), n_trials_dg])\n",
    "\n",
    "# Loop over units\n",
    "for idx_u, unit in enumerate(units):\n",
    "    unit_spikes = ex_probe_spikes[unit]\n",
    "    \n",
    "    # Loop over orientations\n",
    "    for idx_o, ori in enumerate(oris):\n",
    "        tmp = dg_stim[dg_stim.orientation==ori]\n",
    "        \n",
    "        # Loop over trials/sweeps\n",
    "        for idx, start in enumerate(tmp.start):\n",
    "            dg_tr_spikes = unit_spikes[(unit_spikes > start) & (unit_spikes <= start+window)]\n",
    "            \n",
    "            # Calculate firing rate spike/sec\n",
    "            FR = len(dg_tr_spikes)/window\n",
    "            dg_response[idx_u, idx_o, idx]=FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check shape of output\n",
    "dg_response.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Signal correlation: correlation among tuning curves</h3>\n",
    "\n",
    "<p> The signal correlation measures the correlation coefficient between mean responses to different stimuli. For drifting gratings with fixed SF and TF, it tells us how similar/dissimilar the orientation tuning of the two neurons is.\n",
    "<p> We first plot the orientation tuning curves for the two neurons and then calculate the signal correlation\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp0 = dg_response[0,:,:]          #response of neuron 1 for all oris*trials\n",
    "mean_fr_0 = resp0.mean(1)        #mean FR across all 15 trials\n",
    "sem_fr_0 = resp0.std(1)/np.sqrt(n_trials_dg)    #sem across all 15 trials\n",
    "\n",
    "resp1 = dg_response[1,:,:]          #response of neuron 2 for all oris*trials\n",
    "mean_fr_1 = resp1.mean(1)        #mean FR across all 15 trials\n",
    "sem_fr_1 = resp1.std(1)/np.sqrt(n_trials_dg)    #sem across all 15 trials\n",
    "\n",
    "plt.figure()\n",
    "plt.errorbar(x=oris,y=mean_fr_0,yerr=sem_fr_0, label=units[0])\n",
    "plt.errorbar(x=oris,y=mean_fr_1,yerr=sem_fr_1, label=units[1])\n",
    "plt.xticks(oris)\n",
    "plt.ylabel('Firing rate (spikes/second)')\n",
    "plt.xlabel('Orientation (degrees)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<p>Its evident that the two tuning curves are not very similar. This can be seen by computing the signal correlation.\n",
    "<p> Correlation between two lists of numbers can be calculated by first calculating the correlation matrix using **numpy.corrcoef** and looking at the off_diagonal element of the 2 x 2 matrix. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "signal_corr = np.corrcoef(dg_response.mean(2))[0,1]\n",
    "print(signal_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Noise correlation: correlation across trials</h3>\n",
    "\n",
    "Noise correlation is the correlation coefficient of spike count responses to repeated presentations of identical stimuli, under the same behavioral conditions\n",
    "\n",
    "<p>Noise correlation estimates are better with more trials so we'll use the natural scenes (n=50 trials) to show an example noise correlation calculation. \n",
    "<p>Here we'll compute the noise correlation for image 46 that we examined earlier.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example units\n",
    "ex_probe_spikes = data_set.spike_times[ex_probe]\n",
    "units = ex_unit_ids[:2]\n",
    "\n",
    "# Image 46 stim table\n",
    "image_id = 46\n",
    "img_stim = ns_table[ns_table.frame==image_id]\n",
    "n_trials_ns = len(img_stim)\n",
    "\n",
    "# Define mean response matrix with dimension: neuron*trial\n",
    "ns_response = np.zeros([len(units), n_trials_ns])\n",
    "\n",
    "window = 0.5\n",
    "\n",
    "# Loop over units\n",
    "for idx_u, unit in enumerate(units):\n",
    "    unit_spikes = ex_probe_spikes[unit]\n",
    "\n",
    "    # Loop over trials/sweeps\n",
    "    for idx, start in enumerate(img_stim.start):\n",
    "        spikes = unit_spikes[(unit_spikes > start) & (unit_spikes <= start+window)]\n",
    "        # Calculate firing rate spike/sec\n",
    "        FR = len(spikes)/window\n",
    "        ns_response[idx_u, idx]=FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.plot(ns_response[0,:],ns_response[1,:],'o')\n",
    "plt.ylabel('Firing rate cell 2 (spikes/second)')\n",
    "plt.xlabel('Firing rate cell 1 (spikes/second)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noise_corr = np.corrcoef(ns_response[0,:],ns_response[1,:])[0,1]\n",
    "print(noise_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Homework 3.1</b> Compute signal and noise correlation across all drifting grating stimulus parameters and compute average noise correlation. Compare this to signal and noise correlation across all natural scene stimuli.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Cross-correlogram: fast timescale correlations</h3>\n",
    "\n",
    "The cross-correlogram provides a measure of correlations between neurons on a much faster timescale (typically within ~5 ms). We provide a function <b>ccg</b> below that can be used to compute cross-correlograms between pairs of neurons. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-correlogram (CCG)\n",
    "\n",
    "def ccg(train1, train2, binrange, binsize):\n",
    "    \"\"\"\n",
    "    Computes a cross-correlogram for two spike trains.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train1 : numpy array\n",
    "        Primary spike train. Cross-correlogram will be computed relative to spikes in this spike train.\n",
    "    train2 : numpy array\n",
    "        Secondary spike train.\n",
    "    binrange : tuple or list of length=2\n",
    "        Window over which to compute cross correlogram.\n",
    "    binsize : float\n",
    "        Size of bins in cross-correlogram\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    nbins = int((binrange[1]-binrange[0])/binsize)\n",
    "    \n",
    "    diffs = [extract_local(train2,t1,binrange) for t1 in train1]\n",
    "        \n",
    "    diffs = np.hstack(diffs)\n",
    "    diffs = diffs[diffs!=0]\n",
    "\n",
    "    hist, edges = np.histogram(diffs, bins=nbins, range=binrange)\n",
    "        \n",
    "    return edges[1:]-binsize/2, hist /float(len(train1))*100\n",
    "\n",
    "def extract_local(train2,t1,binrange):\n",
    "    \"\"\"\n",
    "    Returns events in `train2` which are within `binrange` of `t1`, aligned to `t1`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train2 : numpy array\n",
    "    t1 : float\n",
    "    binrange : tuple or list of length=2\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    start = np.searchsorted(train2,t1 + binrange[0])\n",
    "    end = np.searchsorted(train2,t1 + binrange[1])\n",
    "\n",
    "    return train2[start:end] - t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spt_0 = ex_probe_spikes[ex_unit_ids[0]]\n",
    "spt_1 = ex_probe_spikes[ex_unit_ids[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot cross-correlogram between spike trains recorded from the two units\n",
    "\n",
    "binsize = 0.001\n",
    "ccg_win = [-0.1005,0.1005] #np.arange(-0.1005,0.1005,binsize)\n",
    "ccg_centers,ccg_vals = ccg(spt_0,spt_1,ccg_win,binsize)\n",
    "\n",
    "#Plot ccg\n",
    "plt.figure()\n",
    "plt.plot(ccg_centers,ccg_vals)\n",
    "ax = plt.gca()\n",
    "ax.axvline(ccg_centers[100],color='gray',linewidth = 0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Homework 3.2:</b> Write function to compute the \"shuffle corrected CCG\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h1>4. Waveform and spike train analysis for cell classification</h1>\n",
    "\n",
    "<ul>\n",
    "    <li>Different cell types can show distinct extracellular action potential waveforms and firing patterns</li>\n",
    "    <li>Here we will plot spike waveforms and inter-spike interval distributions for units in this experiment</li>\n",
    "    <li>We will start by illustrating the classic RS and FS units division</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h3>Spike waveforms: regular spiking (RS) and fast spiking (FS) units</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get spikes waveforms using method on data_set\n",
    "spike_waveforms = data_set.get_waveforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot spike waveform for one unit\n",
    "wv = spike_waveforms[ex_probe][ex_unit_ids[0]]\n",
    "plt.plot(wv)\n",
    "plt.ylabel('Microvolts')\n",
    "plt.xlabel('ms')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 4.1:</b> Compute spike duration for all units in this experiment and plot histogram of values.\n",
    "Hints:\n",
    "<ol>\n",
    "    <li>Concatenate waveforms in a matrix</li>\n",
    "    <li>Compute location of trough and peak using np.argmax() and np.argmin()</li>\n",
    "    <li>Compute difference between time of trough and peak</li>\n",
    "    <li>Plot histogram of spikes duration (time between trough and peak)</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate waveforms into matrix\n",
    "wv = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot 100 waveforms in this data_set\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,4))\n",
    "for w in wv[:100]:\n",
    "    ax.plot(w,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute trough-to-peak duration\n",
    "duration = \n",
    "duration = 1/30000.*duration*1000 # Convert samples to ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot histogram of duration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "<h3>Inter-spike interval (ISI) distributions and bursting</h3>\n",
    "The inter-spike interval histogram shows the timing between spikes from single neuron. This histogram can show key features of firing including the refractory period, bursting, and oscillations.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Example units\n",
    "ex_probe_spikes = data_set.spike_times[ex_probe]\n",
    "unit_spikes = ex_probe_spikes[ex_unit_ids[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make raster plot of single unit spike train for first 600 seconds of recording\n",
    "fig,ax = plt.subplots(1,1,figsize=(15,4))\n",
    "\n",
    "t = (300,400)\n",
    "window_length = 5 # 5 seconds\n",
    "t = np.arange(t[0],t[1],window_length)\n",
    "\n",
    "# Plot 5 second chunks from unit\n",
    "for i,start in enumerate(t):\n",
    "    spk = unit_spikes[(unit_spikes>start) & (unit_spikes<=start+window_length)]\n",
    "    spk = spk - start\n",
    "    ax.plot(spk,i*np.ones_like(spk),'|',markersize=8)\n",
    "\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_title('Spike train for 1 unit over first 10 minutes of experimental session')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Task 4.1:</b> Plot the inter-spike interval distribution with 1 ms bins. Show 2 graphs with different x-limits: (0, 20 ms) and (0, 200 ms). \n",
    "Hint: use the function np.diff to compute the difference between adjacent spike times (i.e. the inter-spike interval).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SOLUTION\n",
    "# Compute inter-spike interval distribution for 1 unit\n",
    "isi = \n",
    "isi =  # convert to ms\n",
    "print(isi[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot ISI distribution as histogram with 1 ms bins\n",
    "fig,ax = plt.subplots(1,2,figsize=(10,4),sharey=True)\n",
    "ax[0].hist(isi,bins=200,range=(0,200))\n",
    "ax[1].hist(isi,bins=200,range=(0,200))\n",
    "ax[1].set_xlim(0,20)\n",
    "plt.ylabel('Count')\n",
    "plt.xlabel('Inter-spike interval (ms)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background: #DFF0D8; border-radius: 3px; padding: 10px;\">\n",
    "<b>Exercise 4.3:</b>\n",
    "<ol>\n",
    "    <li>Get spike times for 50 units with highest SNR and at least 3000 total spikes.</li>\n",
    "    <li>Plot ISI distribution for each unit</li>\n",
    "    <li>Do the ISI distributions vary between cells?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get unit_df with metadata including snr\n",
    "snr_df = data_set.unit_df[data_set.unit_df.structure == 'VISp']\n",
    "snr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sort df by highest snr values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get spike times for 50 units with highest SNR and at least 3000 total spikes\n",
    "\n",
    "\n",
    "\n",
    "# Figure setup\n",
    "fig,ax = plt.subplots(5,10,figsize=(15,7),sharex=True)\n",
    "ax = ax.ravel()\n",
    "\n",
    "# Plot ISI distribution for each unit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in ax:\n",
    "    i.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "<h1>Project ideas</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1. Characterize visual stimulus coding by burst spikes**\n",
    "    * Many cortical cells fire action potential in bursts (ISI < 10 ms).\n",
    "    * Do burst spikes have similar tuning compared to all spikes?\n",
    "    * Is bursting stimulus-dependent?\n",
    "    \n",
    "** 2. \"Excitatory\" versus \"Inhibitory\" responses to natural images.**\n",
    "    * Examination of raster plots to natural images suggests cells have different response types. Some neurons increase firing rate to images while others are suppressed. Is there a logic to these responses? E.g. are \"suppressed\" cells inhibited by all stimuli or is suppression tuned? What fraction of cells show increases/decreases in firing? Does unsupervised clustering reveal enhanced versus suppressed response patterns? Do these response modes vary across areas?\n",
    "\n",
    "** 3. Cell classification using multi-channel waveform, spiking pattern, functional interactions**\n",
    "    * Extracellular recordings can reveal RS and FS classes. \n",
    "    * High-density Neuropixels probes record single cells on multiple channels and this information can be useful for cell classification. (See https://www.biorxiv.org/content/early/2018/07/25/376863).\n",
    "    * Can units be clustered based on spiking pattern ('bursting' vs 'non-bursting')?\n",
    "    * Can spiking pattern, waveform, and functional interaction features be combined to facilitate unsupervised clustering (e.g. k-means) for identifying cell classes?\n",
    "    \n",
    "    \n",
    "** 4. Explore spike count variability as a function of timescale **\n",
    "    * Explore how spike count reliability and precision by examining variability on long (100s of ms) versus short (1-10 ms)timescales. \n",
    "\n",
    "\n",
    "** 5. Temporal dynamics of stimulus decodability**\n",
    "    * How fast can stimuli be decoded from spiking populations? What is the timecourse of decodability in different areas and cortical layers?\n",
    "    \n",
    "    \n",
    "** 6. Compare image decoding using ephys vs ophys measurements**\n",
    "    * Use both EphysObservatory and Ophys BrainObservatory data to compare neural responses estimated with these two modalities. Ephys will likely provide image information on faster timescale. Does Ephys data more information for decoding?\n",
    "  \n",
    "** 7. Data visualization**\n",
    "    * Visualize action potential backpropagation along the Neuropixels probe\n",
    "    * Visualize spike patterns across shank of Neuropixels probe \n",
    "    * Visualize functional interaction network between layers and areas\n",
    "    * Use dimensionality reduction to visualize spiking population dynamics in lower dimensional space\n",
    "    \n",
    "    \n",
    "** 8. Compare backpropagating action potentials in Allen Institute datasets with ground-truth Neuropixels recordings from rat cortex **\n",
    "    * A new preprint (biorxiv) study makes simultaneous patch-clamp and Neuropixels recordings from single neurons providing an important ground-truth dataset: https://www.biorxiv.org/content/early/2018/07/23/370080 (Marques-Smith et al.)\n",
    "    * Compare spatiotemporal action potential properties (e.g action potential backpropagation) measured with Neuropixels from mouse visual cortex and hippocampus (Allen Institute) and ground-truth recordings in rat (Marques-Smith et al.).\n",
    "    * Github repo for external dataset: https://github.com/kampff-lab/sc.io/tree/master/Paired%20Recordings\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
